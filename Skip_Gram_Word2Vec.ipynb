{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Skip_Gram_Word2Vec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP0cJx8kAoLc3nJ9cHL1T8v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EPRADDH/NLP_Natural_Language_Processing_Methods/blob/main/Skip_Gram_Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2zVhZJ6Zsc6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWfnMK3o3pDb"
      },
      "source": [
        "# Skip-gram model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ5UvWHv3lYJ"
      },
      "source": [
        "The Skip-gram model architecture usually tries to achieve the reverse of what the CBOW model does. It tries to predict the source context words (surrounding words) given a target word (the center word).\r\n",
        "\r\n",
        "Considering our simple sentence from earlier,\r\n",
        "\r\n",
        "“the quick brown fox jumps over the lazy dog”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkAT-LDR43Bz"
      },
      "source": [
        "#\"Skip-gram is used to predict the context word for a given target word.the context words can be right side or left side of given word.\"\r\n",
        "\r\n",
        "1. is used to find the nearest words in sequence\r\n",
        "\r\n",
        "2. should be semantically or logically related words.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrx-CaN2GcIn"
      },
      "source": [
        "we feed our skip-gram model pairs of (X, Y) where X is our input and Y is our label. We do this by using [(target, context), 1] pairs as positive input samples where target is our word of interest and context is a context word occurring near the target word and the positive label 1 indicates this is a contextually relevant pair\r\n",
        "\r\n",
        "We also feed in [(target, random), 0] pairs as negative input samples where target is again our word of interest but random is just a randomly selected word from our vocabulary which has no context or association with our target word. Hence the negative label 0indicates this is a contextually irrelevant pair\r\n",
        "\r\n",
        "so model can  learn which pairs of words are contextually relevant and which are not .\r\n",
        "\r\n",
        "and generate similar embeddings for semantically similar words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8MVmiX-G_Ys"
      },
      "source": [
        "Implementing the Skip-gram Model\r\n",
        "\r\n",
        "1. Build the corpus vocabulary\r\n",
        "\r\n",
        "2. Build a skip-gram [(target, context), relevancy] generator\r\n",
        "\r\n",
        "3. Build the skip-gram model architecture\r\n",
        "\r\n",
        "4. Train the Model\r\n",
        "\r\n",
        "5. Get Word Embeddings\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKzOtraejE4P"
      },
      "source": [
        "import numpy as np\r\n",
        "import gensim\r\n",
        "#np.random.seed(13)\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Embedding, Reshape\r\n",
        "from IPython.display import SVG\r\n",
        "from keras.utils import np_utils\r\n",
        "from keras.utils.data_utils import get_file\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.utils.vis_utils import model_to_dot\r\n",
        "from gensim.models import Word2Vec\r\n",
        "from gensim import models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wL51zN7jMSq"
      },
      "source": [
        "path = get_file('alice.txt', origin='http://www.gutenberg.org/files/11/11-0.txt')\r\n",
        "corpus = open(path).readlines()[:300]\r\n",
        "\r\n",
        "corpus = [sentence for sentence in corpus if sentence.count(\" \") >= 2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QazsXQdHjMYW"
      },
      "source": [
        "tokenizer = Tokenizer()\r\n",
        "tokenizer.fit_on_texts(corpus)\r\n",
        "corpus = tokenizer.texts_to_sequences(corpus)\r\n",
        "nb_samples = sum(len(s) for s in corpus)\r\n",
        "V = len(tokenizer.word_index) + 1\r\n",
        "dim = 100\r\n",
        "window_size = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN_kt7ChmVCA"
      },
      "source": [
        "def generate_data(corpus, window_size, V):\r\n",
        "    maxlen = window_size*2\r\n",
        "    for words in corpus:\r\n",
        "        L = len(words)\r\n",
        "        for index, word in enumerate(words):\r\n",
        "            s = index-window_size\r\n",
        "            e = index+window_size+1\r\n",
        "                    \r\n",
        "            in_words = []\r\n",
        "            labels = []\r\n",
        "            for i in range(s, e):\r\n",
        "                if i != index and 0 <= i < L:\r\n",
        "                    in_words.append([word] )\r\n",
        "                    labels.append(words[i])\r\n",
        "\r\n",
        "            x = np.array(in_words,dtype=np.int32)\r\n",
        "            y = np_utils.to_categorical(labels, V)\r\n",
        "            yield (x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwkH7HdLmtql"
      },
      "source": [
        "skipgram = Sequential()\r\n",
        "skipgram.add(Embedding(input_dim=V, output_dim=dim, embeddings_initializer='glorot_uniform', input_length=1))\r\n",
        "skipgram.add(Reshape((dim, )))\r\n",
        "skipgram.add(Dense(V,activation='softmax'))\r\n",
        "#SVG(model_to_dot(skipgram, show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26zX-tP2jMcb"
      },
      "source": [
        "skipgram.compile(loss='categorical_crossentropy', optimizer=\"adadelta\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_b_1iHojMg4",
        "outputId": "209b8472-f235-46b6-e427-78a52950a470"
      },
      "source": [
        "for ite in range(10):\r\n",
        "    loss = 0.\r\n",
        "    for x, y in generate_data(corpus, window_size, V):\r\n",
        "        loss += skipgram.train_on_batch(x, y)\r\n",
        "\r\n",
        "    print(ite, loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 17508.31623983383\n",
            "1 17504.92721414566\n",
            "2 17501.543313503265\n",
            "3 17498.162217617035\n",
            "4 17494.78385782242\n",
            "5 17491.40824842453\n",
            "6 17488.035346984863\n",
            "7 17484.66514635086\n",
            "8 17481.29764509201\n",
            "9 17477.932814598083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxIatGlZjMlu",
        "outputId": "fb74bd81-5f5a-4dbf-c5c5-b589932b1407"
      },
      "source": [
        "f = open('vectors.txt' ,'w')\r\n",
        "f.write(\" \".join([str(V-1),str(dim)]))\r\n",
        "f.write(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlJJUmYRjMqL"
      },
      "source": [
        "vectors = skipgram.get_weights()[0]\r\n",
        "for word, i in tokenizer.word_index.items():\r\n",
        "    f.write(word)\r\n",
        "    f.write(\" \")\r\n",
        "    f.write(\" \".join(map(str, list(vectors[i,:]))))\r\n",
        "    f.write(\"\\n\")\r\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFClP39p1GYA"
      },
      "source": [
        "w2v = gensim.models.KeyedVectors.load_word2vec_format('./vectors.txt', binary=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRscm8HD1OBx",
        "outputId": "2182285a-3adf-4b8a-c49f-ed23bbf02901"
      },
      "source": [
        "w2v.most_similar(positive=['alice'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('way', 0.27920717000961304),\n",
              " ('find', 0.27284398674964905),\n",
              " ('sight', 0.26491814851760864),\n",
              " ('schoolroom', 0.25955334305763245),\n",
              " ('eat', 0.24656961858272552),\n",
              " ('speak', 0.2385406792163849),\n",
              " ('sending', 0.2375614047050476),\n",
              " ('shall', 0.23341995477676392),\n",
              " ('home', 0.22382879257202148),\n",
              " ('matter', 0.22074073553085327)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op5UVFvkIUHG"
      },
      "source": [
        "#Build the corpus vocabulary\r\n",
        "To start off, we will first build our corpus vocabulary where we extract out each unique word from our vocabulary and map a unique numeric identifier to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWbvih4N314M",
        "outputId": "26e8f1d7-f1e9-4dc4-ff18-feea72b3c5fa"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV8o0KLEIas8"
      },
      "source": [
        "data=open('/content/drive/MyDrive/NLP-Natural-Language-Processing-Methods/corona.txt','r',encoding='cp1252')\r\n",
        "corona = [text for text in data if text.count(' ') >= 2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IjELAs_JDNO",
        "outputId": "28399076-50e5-4658-d399-1085f920b4ac"
      },
      "source": [
        "corona"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The speed of transmission is an important point of difference between the two viruses. Influenza has a shorter median incubation period (the time from infection to appearance of symptoms) and a shorter serial interval (the time between successive cases) than COVID-19 virus. The serial interval for COVID-19 virus is estimated to be 5-6 days, while for influenza virus, the serial interval is 3 days. This means that influenza can spread faster than COVID-19. \\n',\n",
              " 'Further, transmission in the first 3-5 days of illness, or potentially pre-symptomatic transmission –transmission of the virus before the appearance of symptoms – is a major driver of transmission for influenza. In contrast, while we are learning that there are people who can shed COVID-19 virus 24-48 hours prior to symptom onset, at present, this does not appear to be a major driver of transmission. \\n',\n",
              " 'The reproductive number – the number of secondary infections generated from one infected individual – is understood to be between 2 and 2.5 for COVID-19 virus, higher than for influenza. However, estimates for both COVID-19 and influenza viruses are very context and time-specific, making direct comparisons more difficult.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvcJwp0MJG54"
      },
      "source": [
        "from keras.preprocessing import text\r\n",
        "\r\n",
        "tokenizer = text.Tokenizer()\r\n",
        "tokenizer.fit_on_texts(corona)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CQjkRVmKCDa"
      },
      "source": [
        "word2id = tokenizer.word_index\r\n",
        "id2word = {v:k for k, v in word2id.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7PH3oJEKF4d",
        "outputId": "9a069f04-478c-43e5-adfb-aa7a273da97c"
      },
      "source": [
        "word2id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'19': 5,\n",
              " '2': 37,\n",
              " '24': 72,\n",
              " '3': 29,\n",
              " '48': 73,\n",
              " '5': 19,\n",
              " '6': 52,\n",
              " 'a': 11,\n",
              " 'an': 39,\n",
              " 'and': 12,\n",
              " 'appear': 82,\n",
              " 'appearance': 26,\n",
              " 'are': 22,\n",
              " 'at': 78,\n",
              " 'be': 18,\n",
              " 'before': 64,\n",
              " 'between': 13,\n",
              " 'both': 94,\n",
              " 'can': 32,\n",
              " 'cases': 50,\n",
              " 'comparisons': 100,\n",
              " 'context': 96,\n",
              " 'contrast': 65,\n",
              " 'covid': 4,\n",
              " 'days': 20,\n",
              " 'difference': 42,\n",
              " 'difficult': 102,\n",
              " 'direct': 99,\n",
              " 'does': 80,\n",
              " 'driver': 35,\n",
              " 'estimated': 51,\n",
              " 'estimates': 93,\n",
              " 'faster': 55,\n",
              " 'first': 57,\n",
              " 'for': 7,\n",
              " 'from': 25,\n",
              " 'further': 56,\n",
              " 'generated': 86,\n",
              " 'has': 44,\n",
              " 'higher': 91,\n",
              " 'hours': 74,\n",
              " 'however': 92,\n",
              " 'illness': 58,\n",
              " 'important': 40,\n",
              " 'in': 33,\n",
              " 'incubation': 46,\n",
              " 'individual': 89,\n",
              " 'infected': 88,\n",
              " 'infection': 48,\n",
              " 'infections': 85,\n",
              " 'influenza': 3,\n",
              " 'interval': 16,\n",
              " 'is': 9,\n",
              " 'learning': 67,\n",
              " 'major': 34,\n",
              " 'making': 98,\n",
              " 'means': 53,\n",
              " 'median': 45,\n",
              " 'more': 101,\n",
              " 'not': 81,\n",
              " 'number': 36,\n",
              " 'of': 2,\n",
              " 'one': 87,\n",
              " 'onset': 77,\n",
              " 'or': 59,\n",
              " 'people': 69,\n",
              " 'period': 47,\n",
              " 'point': 41,\n",
              " 'potentially': 60,\n",
              " 'pre': 61,\n",
              " 'present': 79,\n",
              " 'prior': 75,\n",
              " 'reproductive': 83,\n",
              " 'secondary': 84,\n",
              " 'serial': 15,\n",
              " 'shed': 71,\n",
              " 'shorter': 24,\n",
              " 'specific': 97,\n",
              " 'speed': 38,\n",
              " 'spread': 54,\n",
              " 'successive': 49,\n",
              " 'symptom': 76,\n",
              " 'symptomatic': 62,\n",
              " 'symptoms': 27,\n",
              " 'than': 17,\n",
              " 'that': 31,\n",
              " 'the': 1,\n",
              " 'there': 68,\n",
              " 'this': 30,\n",
              " 'time': 14,\n",
              " 'to': 10,\n",
              " 'transmission': 8,\n",
              " 'two': 43,\n",
              " 'understood': 90,\n",
              " 'very': 95,\n",
              " 'virus': 6,\n",
              " 'viruses': 23,\n",
              " 'we': 66,\n",
              " 'while': 28,\n",
              " 'who': 70,\n",
              " '–': 21,\n",
              " '–transmission': 63}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f98OquyKKoK",
        "outputId": "6e9a471c-bba5-4066-87df-9faf4fea2327"
      },
      "source": [
        "id2word"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'the',\n",
              " 2: 'of',\n",
              " 3: 'influenza',\n",
              " 4: 'covid',\n",
              " 5: '19',\n",
              " 6: 'virus',\n",
              " 7: 'for',\n",
              " 8: 'transmission',\n",
              " 9: 'is',\n",
              " 10: 'to',\n",
              " 11: 'a',\n",
              " 12: 'and',\n",
              " 13: 'between',\n",
              " 14: 'time',\n",
              " 15: 'serial',\n",
              " 16: 'interval',\n",
              " 17: 'than',\n",
              " 18: 'be',\n",
              " 19: '5',\n",
              " 20: 'days',\n",
              " 21: '–',\n",
              " 22: 'are',\n",
              " 23: 'viruses',\n",
              " 24: 'shorter',\n",
              " 25: 'from',\n",
              " 26: 'appearance',\n",
              " 27: 'symptoms',\n",
              " 28: 'while',\n",
              " 29: '3',\n",
              " 30: 'this',\n",
              " 31: 'that',\n",
              " 32: 'can',\n",
              " 33: 'in',\n",
              " 34: 'major',\n",
              " 35: 'driver',\n",
              " 36: 'number',\n",
              " 37: '2',\n",
              " 38: 'speed',\n",
              " 39: 'an',\n",
              " 40: 'important',\n",
              " 41: 'point',\n",
              " 42: 'difference',\n",
              " 43: 'two',\n",
              " 44: 'has',\n",
              " 45: 'median',\n",
              " 46: 'incubation',\n",
              " 47: 'period',\n",
              " 48: 'infection',\n",
              " 49: 'successive',\n",
              " 50: 'cases',\n",
              " 51: 'estimated',\n",
              " 52: '6',\n",
              " 53: 'means',\n",
              " 54: 'spread',\n",
              " 55: 'faster',\n",
              " 56: 'further',\n",
              " 57: 'first',\n",
              " 58: 'illness',\n",
              " 59: 'or',\n",
              " 60: 'potentially',\n",
              " 61: 'pre',\n",
              " 62: 'symptomatic',\n",
              " 63: '–transmission',\n",
              " 64: 'before',\n",
              " 65: 'contrast',\n",
              " 66: 'we',\n",
              " 67: 'learning',\n",
              " 68: 'there',\n",
              " 69: 'people',\n",
              " 70: 'who',\n",
              " 71: 'shed',\n",
              " 72: '24',\n",
              " 73: '48',\n",
              " 74: 'hours',\n",
              " 75: 'prior',\n",
              " 76: 'symptom',\n",
              " 77: 'onset',\n",
              " 78: 'at',\n",
              " 79: 'present',\n",
              " 80: 'does',\n",
              " 81: 'not',\n",
              " 82: 'appear',\n",
              " 83: 'reproductive',\n",
              " 84: 'secondary',\n",
              " 85: 'infections',\n",
              " 86: 'generated',\n",
              " 87: 'one',\n",
              " 88: 'infected',\n",
              " 89: 'individual',\n",
              " 90: 'understood',\n",
              " 91: 'higher',\n",
              " 92: 'however',\n",
              " 93: 'estimates',\n",
              " 94: 'both',\n",
              " 95: 'very',\n",
              " 96: 'context',\n",
              " 97: 'specific',\n",
              " 98: 'making',\n",
              " 99: 'direct',\n",
              " 100: 'comparisons',\n",
              " 101: 'more',\n",
              " 102: 'difficult'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jitsnX4kLGRn"
      },
      "source": [
        "vocab_size = len(word2id) + 1 \r\n",
        "embed_size = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sP_q2H4VLTgM",
        "outputId": "3d33db91-cdfa-4ba7-ab53-ee22530c8ada"
      },
      "source": [
        "wids = [[word2id[w] for w in text.text_to_word_sequence(doc)] for doc in corona]\r\n",
        "print('Vocabulary Size:', vocab_size)\r\n",
        "print('Vocabulary Sample:', list(word2id.items())[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 103\n",
            "Vocabulary Sample: [('the', 1), ('of', 2), ('influenza', 3), ('covid', 4), ('19', 5), ('virus', 6), ('for', 7), ('transmission', 8), ('is', 9), ('to', 10)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2yAflP6Ldz4"
      },
      "source": [
        "# Build a skip-gram [(target, context), relevancy] generator\r\n",
        "\r\n",
        "irrelevant = 0\r\n",
        "relevant = 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_h7x5iYLV_Q",
        "outputId": "0290a504-dfb2-4d69-c99b-8b96587d2256"
      },
      "source": [
        "from keras.preprocessing.sequence import skipgrams\r\n",
        "\r\n",
        "# generate skip-grams\r\n",
        "skip_grams = [skipgrams(wid, vocabulary_size=vocab_size, window_size=10) for wid in wids]\r\n",
        "\r\n",
        "# view sample skip-grams\r\n",
        "pairs, labels = skip_grams[0][0], skip_grams[0][1]\r\n",
        "for i in range(10):\r\n",
        "    print(\"({:s} ({:d}), {:s} ({:d})) -> {:d}\".format(\r\n",
        "          id2word[pairs[i][0]], pairs[i][0], \r\n",
        "          id2word[pairs[i][1]], pairs[i][1], \r\n",
        "          labels[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(interval (16), shed (71)) -> 0\n",
            "(time (14), than (17)) -> 1\n",
            "(the (1), symptoms (27)) -> 1\n",
            "(means (53), 19 (5)) -> 1\n",
            "(median (45), the (1)) -> 1\n",
            "(symptoms (27), shorter (24)) -> 1\n",
            "(a (11), the (1)) -> 1\n",
            "(covid (4), very (95)) -> 0\n",
            "(than (17), means (53)) -> 1\n",
            "(interval (16), shed (71)) -> 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmFemiTrOvrl"
      },
      "source": [
        "#Build the skip-gram model architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS4qpauuUgQF"
      },
      "source": [
        "To build our deep learning architecture for the skip-gram model.our inputs will be our target word and context or random word pair\r\n",
        "\r\n",
        "which are passed to an embedding layer to initialized with random weights of it’s own.Once we obtain the word embeddings for the target and the context word\r\n",
        "\r\n",
        "we pass it to a merge layer where we compute the dot product of these two vectors. \r\n",
        "\r\n",
        "Then we pass on this dot product value to a dense sigmoid layer which predicts either a 1 or a 0 depending on if the pair of words are contextually relevant or just random words (Y’)\r\n",
        "\r\n",
        "We match this with the actual relevance label (Y), compute the loss by leveraging the mean_squared_error loss and perform backpropagation with each epoch to update the embedding layer in the process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "V9snsKuyWZBv",
        "outputId": "4037746e-0b2e-4b0f-cb64-bc9438b5a5ce"
      },
      "source": [
        "from keras.layers import dot\r\n",
        "from keras.layers import Dense, Input\r\n",
        "from keras.layers.core import Reshape\r\n",
        "from keras.layers import Embedding\r\n",
        "from keras.models import  Model\r\n",
        "from keras.backend import reshape\r\n",
        "\r\n",
        "# build skip-gram architecture\r\n",
        "inp = Input(shape=(1,),name = \"first_input\")\r\n",
        "word_model22 = Embedding(input_dim=vocab_size, output_dim=embed_size,\r\n",
        "                         embeddings_initializer=\"glorot_uniform\",\r\n",
        "                         input_length=1)\r\n",
        "emb  = word_model22(inp)\r\n",
        "word_model22 = Reshape(target_shape= (embed_size,))(emb)\r\n",
        "\r\n",
        "inp1 = Input(shape=(1,),name = \"2nd_input\")\r\n",
        "context_model = Embedding(input_dim=vocab_size, output_dim=embed_size,\r\n",
        "                         embeddings_initializer=\"glorot_uniform\",\r\n",
        "                         input_length=1)\r\n",
        "emb1  = context_model(inp1)\r\n",
        "context_model = Reshape(target_shape= (embed_size,))(emb1)\r\n",
        "\r\n",
        "mo = (dot([word_model22, context_model],axes=-1))\r\n",
        "mo = (Dense(1, kernel_initializer=\"glorot_uniform\", activation=\"sigmoid\"))(mo)\r\n",
        "model = Model(inputs = (inp, inp1), outputs =mo)\r\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\")\r\n",
        "\r\n",
        "# view model summary\r\n",
        "print(model.summary())\r\n",
        "\r\n",
        "# visualize model structure\r\n",
        "from IPython.display import SVG\r\n",
        "from keras.utils.vis_utils import model_to_dot\r\n",
        "\r\n",
        "SVG(model_to_dot(model, show_shapes=True, show_layer_names=False, \r\n",
        "                 rankdir='TB').create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-e3efda80fae7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# build skip-gram architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"first_input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m word_model22 = Embedding(input_dim=vocab_size, output_dim=embed_size,\n\u001b[0m\u001b[1;32m     11\u001b[0m                          \u001b[0membeddings_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"glorot_uniform\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                          input_length=1)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vocab_size' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSXh8PM4OGdI"
      },
      "source": [
        "from keras.layers import Input\r\n",
        "from keras.models import Model\r\n",
        "from keras.layers.embeddings import Embedding\r\n",
        "from keras.layers.core import Dense, Reshape\r\n",
        "from keras.layers import dot\r\n",
        "\r\n",
        "input_target = Input((1,))\r\n",
        "input_context = Input((1,))\r\n",
        "\r\n",
        "embedding = Embedding(vocab_size, embed_size, input_length=1, name='embedding')\r\n",
        "\r\n",
        "word_embedding = embedding(input_target)\r\n",
        "word_embedding = Reshape((embed_size, 1))(word_embedding)\r\n",
        "context_embedding = embedding(input_context)\r\n",
        "context_embedding = Reshape((embed_size, 1))(context_embedding)\r\n",
        "\r\n",
        "# now perform the dot product operation  \r\n",
        "dot_product = dot([word_embedding, context_embedding], axes=1)\r\n",
        "dot_product = Reshape((1,))(dot_product)\r\n",
        "\r\n",
        "# add the sigmoid output layer\r\n",
        "output = Dense(1, activation='sigmoid')(dot_product)\r\n",
        "\r\n",
        "model = Model([input_target, input_context],output)\r\n",
        "model.compile(loss='mean_squared_error', optimizer='rmsprop')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T_zRVQeONSI",
        "outputId": "1ca00354-8878-46b6-bded-9ac719c9f563"
      },
      "source": [
        "# view model summary\r\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1, 100)       10300       input_7[0][0]                    \n",
            "                                                                 input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_45 (Reshape)            (None, 100, 1)       0           embedding[2][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_46 (Reshape)            (None, 100, 1)       0           embedding[3][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dot_12 (Dot)                    (None, 1, 1)         0           reshape_45[0][0]                 \n",
            "                                                                 reshape_46[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "reshape_47 (Reshape)            (None, 1)            0           dot_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            2           reshape_47[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 10,302\n",
            "Trainable params: 10,302\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "id": "838UZltL8zcA",
        "outputId": "0ad7b71b-ed6e-42df-bd6a-0641ecc0056b"
      },
      "source": [
        "# visualize model structure\r\n",
        "from IPython.display import SVG\r\n",
        "from keras.utils.vis_utils import model_to_dot\r\n",
        "\r\n",
        "SVG(model_to_dot(model, show_shapes=True, show_layer_names=False, \r\n",
        "                 rankdir='TB').create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"627pt\" viewBox=\"0.00 0.00 426.00 470.00\" width=\"568pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 466)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-466 422,-466 422,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139774776485368 -->\n<g class=\"node\" id=\"node1\">\n<title>139774776485368</title>\n<polygon fill=\"none\" points=\"6,-415.5 6,-461.5 200,-461.5 200,-415.5 6,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"46\" y=\"-434.8\">InputLayer</text>\n<polyline fill=\"none\" points=\"86,-415.5 86,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"115\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"86,-438.5 144,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"115\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"144,-415.5 144,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"172\" y=\"-446.3\">[(?, 1)]</text>\n<polyline fill=\"none\" points=\"144,-438.5 200,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"172\" y=\"-423.3\">[(?, 1)]</text>\n</g>\n<!-- 139774776486320 -->\n<g class=\"node\" id=\"node3\">\n<title>139774776486320</title>\n<polygon fill=\"none\" points=\"99.5,-332.5 99.5,-378.5 318.5,-378.5 318.5,-332.5 99.5,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"141.5\" y=\"-351.8\">Embedding</text>\n<polyline fill=\"none\" points=\"183.5,-332.5 183.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"212.5\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"183.5,-355.5 241.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"212.5\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"241.5,-332.5 241.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"280\" y=\"-363.3\">(?, 1)</text>\n<polyline fill=\"none\" points=\"241.5,-355.5 318.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"280\" y=\"-340.3\">(?, 1, 100)</text>\n</g>\n<!-- 139774776485368&#45;&gt;139774776486320 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139774776485368-&gt;139774776486320</title>\n<path d=\"M132.5269,-415.3799C144.4867,-406.0151 158.445,-395.0855 171.1386,-385.1462\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"173.5481,-387.7049 179.2638,-378.784 169.2325,-382.1934 173.5481,-387.7049\" stroke=\"#000000\"/>\n</g>\n<!-- 139774776485872 -->\n<g class=\"node\" id=\"node2\">\n<title>139774776485872</title>\n<polygon fill=\"none\" points=\"218,-415.5 218,-461.5 412,-461.5 412,-415.5 218,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258\" y=\"-434.8\">InputLayer</text>\n<polyline fill=\"none\" points=\"298,-415.5 298,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"327\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"298,-438.5 356,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"327\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"356,-415.5 356,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"384\" y=\"-446.3\">[(?, 1)]</text>\n<polyline fill=\"none\" points=\"356,-438.5 412,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"384\" y=\"-423.3\">[(?, 1)]</text>\n</g>\n<!-- 139774776485872&#45;&gt;139774776486320 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139774776485872-&gt;139774776486320</title>\n<path d=\"M285.4731,-415.3799C273.5133,-406.0151 259.555,-395.0855 246.8614,-385.1462\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"248.7675,-382.1934 238.7362,-378.784 244.4519,-387.7049 248.7675,-382.1934\" stroke=\"#000000\"/>\n</g>\n<!-- 139774776486208 -->\n<g class=\"node\" id=\"node4\">\n<title>139774776486208</title>\n<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 200,-295.5 200,-249.5 0,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"32.5\" y=\"-268.8\">Reshape</text>\n<polyline fill=\"none\" points=\"65,-249.5 65,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"65,-272.5 123,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"123,-249.5 123,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-280.3\">(?, 1, 100)</text>\n<polyline fill=\"none\" points=\"123,-272.5 200,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.5\" y=\"-257.3\">(?, 100, 1)</text>\n</g>\n<!-- 139774776486320&#45;&gt;139774776486208 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139774776486320-&gt;139774776486208</title>\n<path d=\"M178.6374,-332.3799C166.222,-322.9259 151.7122,-311.8772 138.5604,-301.8625\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"140.6542,-299.0577 130.5778,-295.784 136.4134,-304.6269 140.6542,-299.0577\" stroke=\"#000000\"/>\n</g>\n<!-- 139774776486432 -->\n<g class=\"node\" id=\"node5\">\n<title>139774776486432</title>\n<polygon fill=\"none\" points=\"218,-249.5 218,-295.5 418,-295.5 418,-249.5 218,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250.5\" y=\"-268.8\">Reshape</text>\n<polyline fill=\"none\" points=\"283,-249.5 283,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"312\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"283,-272.5 341,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"312\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"341,-249.5 341,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"379.5\" y=\"-280.3\">(?, 1, 100)</text>\n<polyline fill=\"none\" points=\"341,-272.5 418,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"379.5\" y=\"-257.3\">(?, 100, 1)</text>\n</g>\n<!-- 139774776486320&#45;&gt;139774776486432 -->\n<g class=\"edge\" id=\"edge4\">\n<title>139774776486320-&gt;139774776486432</title>\n<path d=\"M239.3626,-332.3799C251.778,-322.9259 266.2878,-311.8772 279.4396,-301.8625\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"281.5866,-304.6269 287.4222,-295.784 277.3458,-299.0577 281.5866,-304.6269\" stroke=\"#000000\"/>\n</g>\n<!-- 139774776570096 -->\n<g class=\"node\" id=\"node6\">\n<title>139774776570096</title>\n<polygon fill=\"none\" points=\"84.5,-166.5 84.5,-212.5 333.5,-212.5 333.5,-166.5 84.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-185.8\">Dot</text>\n<polyline fill=\"none\" points=\"122.5,-166.5 122.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"151.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"122.5,-189.5 180.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"151.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"180.5,-166.5 180.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-197.3\">[(?, 100, 1), (?, 100, 1)]</text>\n<polyline fill=\"none\" points=\"180.5,-189.5 333.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-174.3\">(?, 1, 1)</text>\n</g>\n<!-- 139774776486208&#45;&gt;139774776570096 -->\n<g class=\"edge\" id=\"edge5\">\n<title>139774776486208-&gt;139774776570096</title>\n<path d=\"M130.3626,-249.3799C142.778,-239.9259 157.2878,-228.8772 170.4396,-218.8625\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"172.5866,-221.6269 178.4222,-212.784 168.3458,-216.0577 172.5866,-221.6269\" stroke=\"#000000\"/>\n</g>\n<!-- 139774776486432&#45;&gt;139774776570096 -->\n<g class=\"edge\" id=\"edge6\">\n<title>139774776486432-&gt;139774776570096</title>\n<path d=\"M287.6374,-249.3799C275.222,-239.9259 260.7122,-228.8772 247.5604,-218.8625\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"249.6542,-216.0577 239.5778,-212.784 245.4134,-221.6269 249.6542,-216.0577\" stroke=\"#000000\"/>\n</g>\n<!-- 139774776569928 -->\n<g class=\"node\" id=\"node7\">\n<title>139774776569928</title>\n<polygon fill=\"none\" points=\"116.5,-83.5 116.5,-129.5 301.5,-129.5 301.5,-83.5 116.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"149\" y=\"-102.8\">Reshape</text>\n<polyline fill=\"none\" points=\"181.5,-83.5 181.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"181.5,-106.5 239.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"239.5,-83.5 239.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"270.5\" y=\"-114.3\">(?, 1, 1)</text>\n<polyline fill=\"none\" points=\"239.5,-106.5 301.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"270.5\" y=\"-91.3\">(?, 1)</text>\n</g>\n<!-- 139774776570096&#45;&gt;139774776569928 -->\n<g class=\"edge\" id=\"edge7\">\n<title>139774776570096-&gt;139774776569928</title>\n<path d=\"M209,-166.3799C209,-158.1745 209,-148.7679 209,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"212.5001,-139.784 209,-129.784 205.5001,-139.784 212.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139774776572280 -->\n<g class=\"node\" id=\"node8\">\n<title>139774776572280</title>\n<polygon fill=\"none\" points=\"130.5,-.5 130.5,-46.5 287.5,-46.5 287.5,-.5 130.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"156.5\" y=\"-19.8\">Dense</text>\n<polyline fill=\"none\" points=\"182.5,-.5 182.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"182.5,-23.5 240.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"240.5,-.5 240.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264\" y=\"-31.3\">(?, 1)</text>\n<polyline fill=\"none\" points=\"240.5,-23.5 287.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264\" y=\"-8.3\">(?, 1)</text>\n</g>\n<!-- 139774776569928&#45;&gt;139774776572280 -->\n<g class=\"edge\" id=\"edge8\">\n<title>139774776569928-&gt;139774776572280</title>\n<path d=\"M209,-83.3799C209,-75.1745 209,-65.7679 209,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"212.5001,-56.784 209,-46.784 205.5001,-56.784 212.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "956b9Dtz9HcQ",
        "outputId": "f0748fac-0c8c-41c5-c9c7-c8f28fffa587"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "for epoch in range(1, 6):\r\n",
        "    loss = 0\r\n",
        "    for i, elem in enumerate(skip_grams):\r\n",
        "        pair_first_elem = np.array(list(zip(*elem[0]))[0], dtype='int32')\r\n",
        "        pair_second_elem = np.array(list(zip(*elem[0]))[1], dtype='int32')\r\n",
        "        labels = np.array(elem[1], dtype='int32')\r\n",
        "        X = [pair_first_elem, pair_second_elem]\r\n",
        "        Y = labels\r\n",
        "        if i % 10000 == 0:\r\n",
        "            #print('Processed {} (skip_first, skip_second, relevance) pairs'.format(i))\r\n",
        "            loss += model.train_on_batch(X,Y)  \r\n",
        "\r\n",
        "    print('Epoch:', epoch, 'Loss:', loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 Loss: 0.24751104414463043\n",
            "Epoch: 2 Loss: 0.2471613585948944\n",
            "Epoch: 3 Loss: 0.2468196153640747\n",
            "Epoch: 4 Loss: 0.24647873640060425\n",
            "Epoch: 5 Loss: 0.24613448977470398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln4JhrTx-MmX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8NtP4_3Vxuk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b75jvz1JUYrT"
      },
      "source": [
        "# Skipgram word2Vec_model using tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95Mt8lJjo0p7"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import string\r\n",
        "import nltk\r\n",
        "import pandas as pd\r\n",
        "from sklearn.manifold import TSNE\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhztkS7FUozP"
      },
      "source": [
        "\r\n",
        "data_file = \"/content/drive/MyDrive/NLP-Natural-Language-Processing-Methods/THE _AVENGERS.txt\"\r\n",
        "f = open(data_file, \"r\",encoding='cp1252')\r\n",
        "raw_data = f.read()\r\n",
        "raw_data = raw_data[:50000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAj0gaOjWey-"
      },
      "source": [
        "# Cleaning data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaxUtOZ1Vadj"
      },
      "source": [
        "def clean_text(text):\r\n",
        "    text = text.lower()\r\n",
        "\r\n",
        "\r\n",
        "    text =  text.replace(\"\\n\", \"\")\r\n",
        "    text = text.replace(\"\\xad\", \"\")\r\n",
        "    text = text.replace(\"'ve\", \" have\")\r\n",
        "    text = text.replace(\"'t\", \" not\")\r\n",
        "    text = text.replace(\"'s\", \" is\")\r\n",
        "    text = text.replace(\"'m\", \" am\")\r\n",
        "\r\n",
        "    ## Specific Words\r\n",
        "    text = text.replace(\"p.e.g.a.s.u.s\", \"pegasus\")\r\n",
        "    text = text.replace(\"s.h.i.e.l.d.\", \"shield\")\r\n",
        "    text = text.replace(\"s.h.i.e.l.d\", \"shield\")\r\n",
        "    text = text.replace(\"(v.o.)\", \"(vo)\")\r\n",
        "    text = text.replace(\"dr.\", \"dr\")\r\n",
        "    text = text.replace(\"...\", \"\")\r\n",
        "    text = text.replace(\"'\", \"\")\r\n",
        "    text = text.replace('\"', \"\")\r\n",
        "\r\n",
        "    ## Numbers with Word\r\n",
        "    text = text.replace(\"0\", \" zero \")\r\n",
        "    text = text.replace(\"1\", \" one \")\r\n",
        "    text = text.replace(\"2\", \" two \")\r\n",
        "    text = text.replace(\"3\", \" three \")\r\n",
        "    text = text.replace(\"4\", \" four \")\r\n",
        "    text = text.replace(\"5\", \" five \")\r\n",
        "    text = text.replace(\"6\", \" six \")\r\n",
        "    text = text.replace(\"7\", \" seven \")\r\n",
        "    text = text.replace(\"8\", \" eight \")\r\n",
        "    text = text.replace(\"9\", \" nine \")\r\n",
        "\r\n",
        "    punc = set(string.punctuation)\r\n",
        "    for p in punc:\r\n",
        "        if p != \".\":\r\n",
        "            #text = text.replace(p, \" \" + p + \" \")\r\n",
        "            text = text.replace(p, \" \")\r\n",
        "\r\n",
        "    text = \" \".join(text.split())\r\n",
        "\r\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "voHTI7gkXBfp",
        "outputId": "22fb770f-5557-48ca-eaa5-a0bd929f9d3e"
      },
      "source": [
        "data = clean_text(raw_data)\r\n",
        "\r\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'skip to contentsearch or jump to…pull requestsissuesmarketplaceexplore epraddh nikhilroxtomar word two vec one two zero codeissuespull requestsactionsprojectswikisecurityinsightsword two vec avengers two zero one two .txt nikhilroxtomarnikhilroxtomar add files via uploadlatest commit seven five five six b two a on feb nine two zero one nine history one contributor five nine three two lines four three seven nine sloc one nine two kb the avengers written by joss whedon and there came a day a day unlike any other when earth is mightiest heroes and heroines found themselves united against a common threat. on that day the avengers were born to fight the foes no single superhero could withstand through the years their roster has prospered changing many times but their glory has never been denied heed the call then for now the avengers assemble burning blue flames. a smoky cube shape emerges the tesseract. filling the screen with blackness. cut to ext. throne room space night kneeling behind a throne a clothed armored figure known as the other bows. the other vo the tesseract has awakened. it is on a little world. a human world. they would wield its power cut to the other faces a horned shaped shadow. loki. loki is handed the chitauri scepter a long golden handle fitted with a blue gem encircled with silver blades. the other vo but our ally knows its workings as they never will. he is ready to lead. and our force our chitauri will follow. high wide on tens of thousands of chitauri stand ready in a seething mass of neat rows and columns.the ground simply quakes. the other vo the world will be his. the universe yours. and the humans what can they do but burn cut to ext. shield project pegasus facility night out in the new mexico desert a remote research facility is in a state of panic. it is an evacuation. a swooping helicopter flies in. chaos. men in suits run around like in the typical we have to leave fashion. soldiers on foot jump onto humvees accelerating the hell out of there. a voice bellows from hidden loudspeakers. ext. helicopter pad continuous standing a few yards from the landing pad a fed in a suit with badass shades peers at the helicopter as it lands. this is shield agent phil coulson. walking out of the helicopter is shield agent maria hill sexy fierce and determined. following her shield director nick fury climbs out. hill and fury approach agent coulson. nick fury how bad is it agent phil coulson that is the problem sir. we don not know. int. facility floor night agent coulson leads hill and fury through the radiation section of the facility. hundreds of technicians and other staff run around taking only the essentials. agent phil coulson dr selvig read an energy surge from the tesseract four hours ago. nick fury nasa didn not authorize selvig to test phase. agent phil coulson he wasn not testing it he wasn not even in the room. spontaneous advancement. agent maria hill it just turned itself on nick fury what are the energy levels now agent phil coulson climbing. when selvig couldn not shut it down we ordered the evac. nick fury how long to get everyone out agent phil coulson campus should be clear in the next half hour. nick fury do better. continuously heading down to radiation facility floor agent maria hill sir evacuation may be futile. nick fury we should tell them to go back to sleep agent maria hill if we can not control the tesseract is energy there may not be a minimum safe distance. nick fury i need you to make sure that phase two prototypes are shipped out. agent maria hill sir is that really a priority right now nick fury until such time as the world ends we will act as though it intends to spin on. clear out the tech below. every piece of phase two on a truck and gone. agent maria hill yes sir. to standing agents with me. int. nasa space radiation facility vacuum chamber continuous fury enters the lab facility where the tesseract is being held by a compact muon solenoid coil chamber. nick fury talk to me doctor. dr erik selvig emerges from behind the cms machine concerned. the tesseract is glowing unusually brighter and flare rings shoot out at random. selvig director. nick fury is there anything we know for certain selvig tesseract is misbehaving. nick fury is that supposed to be funny selvig no it is not funny at all. the tesseract is not only active she ismisbehaving. nick fury how soon until you pull the plug selvig she is an energy source. if we turn off the power she turns it back on. if she reaches peak level nick fury we have prepared for this doctor. harnessing energy from space. selvig we don not have the harness. our calculations are far from complete. now she is throwing off interference radiation. nothing harmful low levels of gamma radiation. nick fury that can be harmful. where is barton selvig the hawk up in his nest as usual. we see clint barton dressed in black tactical gear is up on the railings watching them below fury calls barton on his earpiece. nick fury agent barton report. barton rappels down from the catwalk. walks up to fury. they both walk around the facility in a discreet manner. nick fury i gave you this detail so you could keep a close eye on things. clint barton well i see better from a distance. nick fury are you seeing anything that might set this thing off nasa scientist to selvig doctor it is spiking again. clint barton no one is come or gone. it is oven is clean. no contacts no i.m. is. if there was any tampering sir it wasn not at this end. nick fury at this end clint barton yeah the cube is a doorway to the other end of space right the doors open from both sides. dr selvig clacks away at the keyboard and sees on the monitoring his worst nightmares. suddenly the tesseract thunders and shakes the entire facility. big enough where both agents hill and coulson can feel and theyre at different ends of the facility. the flaring rings and glow of the cube spout out brighter and louder like a boiling pot of water. the tesseract is energy builds up into a beam much like the bifrost bridge which hits at the end of a platform that is wired to the cms device. the great maelstrom beam fires the tesseract energy. the beam then forms a vortex which then opens up a portal. a black hole is created. from the portal the blackness of space beautiful and mysterious strewn with a billion stars appears and a gust of blue energy clouds fill the room blinding everyone. the tesseract is energy forms into a cloud that reaches to the top the facility is vacuum chamber ceiling. it is abnormally quiet. then heavy breathing is heard from the platform. shield guards slowly approach weapons in hands. a figure is kneeling on the platform smoke coming off it. it is loki. smiling in his mischievous manner he raises his head. the smile dies down. he looks deep into the eyes of fury barton and selvig. he stands up holing the scepter. nick fury sir please put down the spear loki looks at his spear then suddenly points it at where fury and barton are standing and shoots out a blue exploding light towards them. barton tackles fury and they both barely miss loki is fired shot. all hell breaks. machine gun fire is shot at loki but the bullets bounce off him like a boss. loki jumps high from the platform and attacks those firing at him. in the blink of an eye loki takes down several guards with his knives and energy blasts from the scepter. he stops and waits to see who will attack him next. honestly the whole lab has almost gone to shit. barton tries to stand up. loki quickly walks towards him. barton raises his gun but loki grabs barton is hand. loki you have heart. loki points the head of his spear at barton is head. barton is eyes suddenly glow black. the ability to control barton is mind is now in loki is hand. barton puts his piece away and stands straight. as loki is busy using his abilities to control the minds of several shield personnel fury takes the tesseract placing it back into its case and tries to leave the lab.then loki please don not. i still need that. nick fury turning this doesn not have to get any messier. loki of course it does. i have come too far for anything else. i am loki of asgard and i am burdened with glorious purpose. selvig loki brother of thor nick fury we have no quarrel with your people. loki an ant has no quarrel with a boot. nick fury you planning to step on us loki i come with glad tidings of a world made free. nick fury free from what loki freedom. freedom is life is great lie. once you accept that in your heart like a gunslinger loki turns to face selvig who is standingbehind him and places his spear against selvig is heart. selvig is eyes glow black. loki you will know peace. nick fury yeah you say peace i kind of think you mean the other thing. from the vacuum chamber ceiling tesseract is energy cloud rapidly builds into what may be an implosion. clint barton sir director fury is stalling. this place is about to blow. drop a hundred feet of rock on us. he means to bury us. nick fury like the pharaohs of odin. selvig he is right. the portal is collapsing in on itself. you got maybe two minutes before this goes critical. loki well then loki looking at barton who doesn not even hesitate shoots fury who falls to the ground. barton grabs the case containing the tesseract and leaves the lab with loki selvig and the other shield personnel loki is controlling. int. pegasus bunker entrance of exiting tunnel night loki barton selvig and the other shield personnel are in the parking lot of the facility quickly gathering certain weapons. agent hill watches in confusion referring to loki. clint barton pointing to the loki team need these vehicles. agent maria hill who is that clint barton he didn not tell me. agent hill looks suspiciously at them as they get into the truck and turns to leave as she is walking away nick fury through the walkie talkie hill do you copy loki and barton sharply look at agent hill. back at the lab fury is sitting up pulling out the bullet breathing heavily. nick fury barton is int. pegasus bunker night suddenly hill turns to shoot at barton but barton is already pointing his gun at her and starts shooting he moves the driver is seat of the truck and drives off as hill keeps shooting. back at the lab fury is holding his side running. nick fury he is got the tesseract track it down the energy is really brewing a fucking shit storm from the vacuum chamber ceiling. int. pegasus bunker tunnel night agent hill slips into a jeep and follows after barton is truck.loki is trucks screech across the tunnel. several shield trucks pull up to them. a drive by shooting ensues. loki who stands on top of the bed of the truck uses his scepter and emits energy blasts flipping over shield trucks. they get in the cars roar out after them. agent hill puts herself at a distance. int. facility floor night fury races out of the hallway avoiding falling pipes. the entire facility is now in a full earthquake. int. facility floor elsewhere continuous agent coulson and several shield agents fall down the steps dropping silver cases of information. they attempt to grab them but agent phil coulson no leave it they run out of there like a bat from hell. int. pegasus tunnel night agent hill is jeep roars out of a side of barton is truck and pulls up alongside them on the left. she goes way ahead and pulls her brake swerving into a three six zero facing barton is truck and driving in reverse. barton is arms reach out the open window and opens fire. agent hill figures fuck it and shoots her windshield opening fire on barton. ext. van night agent coulson jumps into a shield van. on his walkie agent phil coulson youre clear sir you need to go ext. helicopter pad continuous fury bolts out of the facility and jumps into a helicopter. the surface of the pad gives way plunging the helicopter through the surface. but fury is chopper barely makes it out. int. pegasus tunnel night still in a chase and drive by sequence barton is pushes the pedal harder which causes agent hill is jeep to wobble out and put her back behind. int. radiation facility vacuum chamber night the tesseract is energy cloud now shrinks into a small ball of white light. then a cloud of blue light consumes the entire facility and parts of the desert. fury watches from below a rapid build up into what may be an implosion. several miles away agent coulson is van feels a jolt of the tesseract is blastwave. the entire facility swallows into itself a terrifying unimaginable implosion. int. pegasus tunnel night the blastwave of the tesseract causes the tunnel to cave it. like an ocean wave blinding crumbles of falling rock fall onto agent hill is jeep leaving her nearly trapped under this blanket of rock. on the barton is truck they escape the tunnel and drive into the desert landscape. fury is helicopter roars over barton is truck. loki looks up. from the chopper is door it slides open and fury stands there holding a gun shooting at barton is giving an honoring image of jules winnfield. loki looks at fury and in a fit of rage points his scepter shoots out the blue light. the chopper catches on fire going down in a fiery ball. fury like the boss he is jumps out and touches down onto the desert floor. the chopper barrels along the ground. fury coming back to his senses fires at loki but theyre toofar and too late. loki looks back smiling. fury stands there mind reeling. then agent phil coulson walkie talkie director director fury do you copy nick fury the tesseract is with the hostile force. i have men down. hill int. pegasus tunnel night agent hill climbs out her jeep which is sandwiched in but luckily not her. agent maria hill a lot of men still under don not know how many survivors. ext. desert night nick fury sound the general call. i want every living soul not working rescue looking for that brief case. agent maria hill walkie talkie roger that. nick fury coulson get back to base. this is a level seven. as of right now we are at war. a beat. agent phil coulson walkie talkie what do we do fury stands there. thinking. he looks up. on his face is sign of hope. the avengers ext. russia solenski plaza three rd floor night out in the outskirts near a railroad a still in construction building is being occupied by georgi luchkov a large russian general along with his thugs. tall thug is in the middle of a brutal beating on natasha romanoff a slewing foxy unbelievably sexy spy. he backhands natasha is face. she feels the pain but does not breakdown. luchkov smiling walks up to her. dialogue is in russian. luchkov this is not how i wanted the evening to go. natasha i know how you wanted this evening to go. believe me this is better. luchkov id like to know why they sent you to carry out a carrier a stained glass and other random items. tall thug rocks her chair back balancing her off the edge of an open floor. natasha is now scared. natasha i thought general soholob was in charge of the export business. luchkov soholob your reputation is quite a progression. the famous black widow. nothing but a pretty face. natasha you really think i am pretty luchkov slowly walks over to a table filled with tools. he picks up a pair of pliers. tall thug opens up her mouth wide open. luchkov we do not need the lermontov to transfer the tanks. tell him well in english you may have to write it down. suddenly weaselly thug is cell rings. confused he answers. weaselly thug ya looks at luchkov it is for you. luchkov takes the phone pissed. luchkov who the hell is agent phil coulson youre at one one four solenski plaza three rd floor. we have an f two two exactly eight miles out. put the woman on the phone or i will blow up the block before you can make the lobby. holy shit. luchkov places the cell phone against natasha is ear seeing how she is tied to a chair with her hands tied behind her back. agent phil coulson we need you to come in. natasha are you kidding i am working agent phil coulson this takes precedence. natasha i am in the middle of an interrogation and this moron is giving me everything. luchkov i don not give everything. natasha gives him a look. natasha look you can not pull me out of this right now. agent phil coulson natasha. barton is been compromised. a beat. natasha let me put you on hold. she nods to luchkov. as luchkov comes to take the phone off her natasha hits him with her leg and headbuuts him. like a spider she stands up elegantly and starts attacking tall thug by kickboxing him in the face. still tied she rolls over weaselly thug after she trips him. she then stomps on tall thug foot with peg of the chair then knocks him out with her head. yeah during all this coulson is still waiting on the line. she then flips over and falls down hard on weaselly thug breaking the chair. she sees tall thug stand. giving her momentum she runs at him drop kicking him falls down and flips right back up and wraps her legs around his neck and knocks him out cold. she grabs luchkov wraps his leg around with a hanging chain and drops him down the open floor dangling. she picks up the phone and her heels like a boss. natasha where is barton now agent phil coulson we don not know. natasha but he is alive. agent phil coulson we think so. ill brief you on everything when you get back. but first we need you to talk to the big guy. natasha coulson you know that stark trusts me about as far as he can throw me. agent phil coulson no i have got stark. you get the big guy. natasha bozhe moi. ext. indian slum night a little girl runs through the crowd trying to force a way through. int. shack night a tiny shack. the little girl runs up the steps only to be stopped by an attending woman. then the little girl spots him. bruce banner their local doctor. attending woman what are doing here get out you shouldn not be here little girl i have to see the doctor it is my father banner calm down. what is wrong little girl my father banner looks behind him seeing how the girl is staring at a few people lying down looking very sick. banner is he like them the little girl holds out all the money she has in the world. little girl please. ext. slums continuous banner and the little girl hastily run nearly to the edge of town. the little girl gets ahead of herself. banner spots local government car he turns around blocking any view of him. ext int. little girl is shack night banner quickly follows the little girl inside her house. as he walks in the little girl escapes through the window. banner is left standing there like a dumbass. banner should have got paid up front banner. natasha then appears from behind the curtains. banner turns around quietly. natasha you know for a man who is supposed to be avoiding stress you picked a hell of a place to settle. banner avoiding stress isn not the secret. natasha then what is it yoga banner you brought me to the edge of the city smart. i uh assume the whole place is surrounded natasha just you and me. banner and your actress buddy is she a spy too do they start that young natasha i did. banner who are you natasha natasha romanoff. banner are you here to kill me miss romanoff because that is not gonna work out for everyone. natasha no. no. of course not. i am here on behalf of shield. banner shield. how did they find me natasha we never lost you doctor. we have kept our distance even helped keep some other interested parties off your scent. banner why natasha nick fury seems to trust you. but now i need you to come in. banner what if i said no natasha ill persuade you. banner and what if the other guy says no natasha you have been more than a year without an incident. i don not think you wanna break that streak. banner i don not always get what i want. natasha doctor were facing a potential global catastrophe. banner well those i actively try to avoid. natasha this is the tesseract. it has the potential energy to wipe out the planet. she shows him a photo of the tesseract on her cell phone. banner takes a closer look. banner what does fury want me to do swallow it natasha well he wants you to find it. it is been taken. it emits a gamma signature that is too weak for us to trace. there is no one that knows gamma radiation like you do. if there was that is where id be. banner so fury isn not after the monster natasha not that he is told me. banner and he tells you everything natasha talk to fury he needs you on this. banner he needs me in a cage natasha no one is gonna put you in a banner stop lying to me the thunderous tone in is voice makes natasha quickly grab her gun and point it at him but something is now off in the atmosphere. banner stands straight up smiling. banner i am sorry that was mean. i just wanted to see what youd do. why don not we do this the easy way where you don not use that and the other guy doesn not make a mess okay natasha natasha still wary doesn not lower her gun. she lowers her gun and speaks into her earpiece. natasha stand down. were good here. ext. outside the little girl is shack night amazingly dozens of shield agents are surrounding the shack outside. int. little girl is shack night banner looks at natasha charming a smile at her. banner just you and me natasha fidgets now that she exposed her guard down. int. shield analytical room night fury is facing several large monitors as he as a conference with members of the world security council. world security council one this is out of line director. youre dealing with forces you can not control. nick fury you ever been in a war councilman in a firefight did you feel an overabundance of control world security council one you saying that this asgard has declared war on our planet nick fury not asgard. loki. world security council two he can not be working alone. what about the other one his brother. nick fury our intelligence says thor is not a hostile. but he is worlds away we can not depend on him to help. it is up to us. world security council one which is why you should be focusing on phase two it was designed for exactly nick fury phase two isn not ready our enemy is. we need a response team. world security council one the avengers initiative was shut down. nick fury this isn not about the avengers. world security council one were running the world is greatest covert security network and youre gonna leave the fate of human race to a handful of freaks. nick fury i am not leaving anything to anyone. we need a response team. these people maybe isolated unbalanced even but i believe with the right push they can be exactly what we need. world security council two you believe world security council one war isn not won by sentiment director. nick fury no it is won by soldiers. int. brooklyn gym night somewhere in an old almost wwii esque boxing gym steve rogers a man out of time the first avenger fuckin captain america is pummeling a punching bag. with every swing it is like a memory he is trying to fight off and repress. ext. hydra base day flashback captain america is running through the forest dodging mortars gunfire and the tesseract is energy firearms. steve vo there is not enough time i gotta put her in the water int. brooklyn gym night steve is rage keeps building as he punches the bag. it gets harder int. horten h.xviii red skull is ship day flashback steve places his compass with an image of peggy carter. the time is here for him to crash the plane. int. brooklyn gym night steve closes his eyes. goes at the bag harder. peggy vo you won not be alone. int. horten h.xviii red skull is ship day flashback the red skull picks up the tesseract. int. brooklyn gym night steve opens his eyes and fuckin tears the bag as the last memory kicks in. i don not think he can physically stop shield scientist vo oh my god int. project pegasus antarctica day flashback a half frozen steve roger is lying down on a medical slab. two shield scientists run over hi tech devices to see if his vitals are up. and it seems shield scientist this guy is still alive int. brooklyn gym night steve fucking tears the bag open off its chain spilling out the sand. he stands breathing hard letting out seven zero years of over repressed feeling. after taking a few breathers steve picks up another punching bag which is laying next another dozen bags. he hooks the bag up and starts punching again. fury walks in. nick fury trouble sleeping steve i slept for seventy years sir. i think i have had my fill. nick fury then you should be out celebrating seeing the world. steve stops punching and walks over to the bench unraveling the tape off his hands. he sits down. steve i went under the world was at war i wake up they say we won. they didn not say what we lost. nick fury we have made some mistakes along the way. some very recently. steve you here with a mission sir nick fury i am. steve trying to get me back in the world nick fury trying to save it. fury hands steve a file on the tesseract along with other files on hydra is projects. steve hydra is secret weapon. nick fury howard stark fished that out of the ocean when he was looking for you. he thought what we think the tesseract could be the key to unlimited sustainable energy. that is something the world sorely needs. steve who took it from you nick fury he is called loki. he is not from around here. there is a lot well have to bring you up to speed on if youre in. the world has gotten even stranger than you already know. steve at this point i doubt anything would surprise me. nick fury ten bucks says youre wrong. there is a debriefing package waiting for you back at your apartment. steve turns and picks up a punching bag. starts walking out of the gym. nick fury is there anything you can tell us about the tesseract that we ought to know now steve you should have left it in the ocean. int. ocean night out in the atlantic ocean tony stark in his iron man suit is cutting a pipeline transport with a laser cutter coming from his hand. he then places a stark energy reactor. it lights up. iron man rockets out of the water and flies towards stark tower. tony youre good on this end. the rest is up to you. pepper potts on the other line you disconnected the transition lines are we off the grid inside the suit pepper appears on his hud monitor. tony stark tower is about to become a beacon of self sustaining clean energy. pepper wow. so maybe our reactor takes over and it actually works tony i assume. light her up. as iron man flies to the stark tower building the power is switched on and the stark sign lights up. pepper how does it look tony like christmas but with more me. pepper gotta go wider on the public awareness campaign. you need to do some press. i can do some more tomorrow. i am working on the zoning for the next billboards. tony pepper youre killing me. remember enjoy the moment. pepper then get in here and i will. tony arrives at his skyscraper penthouse and is in the process of taking off his iron man suit through a hi tech gauntlet of gadgets. jarvis sir agent coulson of shield is on the line. tony i am not in. i am actually out. jarvis sir i am afraid he is insisting. tony close the line jarvis. i got a date. int. tony is penthouse night pepper potts stares up at the monitors of the reactor device. pepper levels are holding steady i think. tony of course they are i was directly involved. which brings me to my next question how does it feel to be a genius pepper well ha i really wouldn not know now would i tony what do you mean all this came from you. pepper no. all this came from that. points to the energy in his chest plate. tony give yourself some credit please. stark tower is your baby. give yourself twelve percent of the credit. pepper twelve percent tony an argument can be made for fifteen. pepper twelve percent for my baby tony well i did do all the heavy lifting. literally i lifted the heavy things. and sorry but the security snafu that was on you. pepper oooooh. tony my private elevator pepper you mean our elevator tony was teeming with sweaty workmen. i am going to pay for that comment about percentages in some subtle way later aren not i pepper pours herself and tony a glass of champagne. pepper not gonna be that subtle. tony ill tell you what. next building is gonna say potts on the tower. pepper on the lease. tony call your mom can you bunk over jarvis sir the telephone. i am afraid my protocols are being overwritten. agent phil coulson stark we need to talk. tony picks up his phone and looks into it at coulson. tony you have reached the life model decoy of tony stark please leave a message. agent phil coulson this is urgent. tony then leave it urgently. at that moment the elevator door opens and coulson appears. tony security breach. to pepper that is on you. agent phil coulson mr. stark. pepper phil come in. tony phil uh his first name is agent. pepper come on in were celebrating. tony which is why he can not stay. agent phil coulson we need you to look this over. he holds out a file towards stark soon as possible. tony i don not like being handed things. pepper that is alright cause i love to be handed things. so let is trade. she passes her glass of champagne to coulson and takes the file from him then takes her champagne glass back from coulson and passes the file over to stark. pepper thank you. tony official consulting hours are between eight and five every other thursday. agent phil coulson this isn not a consultation. pepper is this about the avengers which ii know nothing about. tony the avengers initiative was scrapped i thought. and i didn not even qualify. pepper i didn not know that either. tony yeah apparently i am volatile self obsessed don not play well with others. pepper that i did know. agent phil coulson this isn not about personality profiles anymore. tony whatever. miss potts got a minute pepper walks over to tony who places the files into his own databases. tony you know i thought we were having a moment. pepper i was having twelve percent of a moment. this seems serious phil is pretty shaken. tony how did you notice why is he phil pepper what is all of this tony this is uh tony expands his arms and different profiles appear in holographic form floating in the air in front of tony and pepper. tony this. screens appear of captain america in action the hulk roaring as he attacks the army at culver university thor fighting the destroyer and another is of loki and the tesseract to which stark and pepper look on in awe. pepper i am going to take the jet to d.c. tonight. tony tomorrow. pepper you have got homework. you have got a lot of homework. tony well what if i didn not pepper if you didn not tony yeah. pepper you mean if you finished stark nods his head well umthen she whispers something in his ear. tony gasps. coulson looks away in embarrassment. tony square deal. it is the last date. pepper kisses him. pepper work hard. as pepper leaves with agent coulson tony grabs the tesseract in holograph form worried. int. quinjet day inside the quinjet steve is sitting down holding a tablet watching the footage of the hulk is attack on the army at culver university. pilot were about forty minutes out from base sir. agent coulson stands up from his seat and walks over to steve. steve so this doctor banner was trying to replicate the serum that was used on me agent phil coulson a lot of people were. you were the world is first superhero. banner thought gamma radiation might hold the key to unlocking erskine is original formula. the hulk roars with fury as he slams a jeep apart. steve didn not really go his way did it agent phil coulson not so much. when he is not that thing though guy is like a stephen hawking. steve looks confused. agent phil coulson he is like a smart person. i gotta say it is an honor to meet you officially. steve smiles at coulson. agent phil coulson i sort of met you i mean i watched you while you were sleeping. steve looks down. he stands up closes his laptop and walks to the side with coulson following. agent phil coulson i mean i was i was present while you were unconscious from the ice. you know it is really it is just a just a huge honor to have you on board. steve well i hope i am the man for the job. agent phil coulson oh you are. absolutely. uh we have made some modifications to the uniform. i had a little design input. steve the uniform aren not the stars and stripes a little old fashioned agent phil coulson with everything that is happening the things that are about to come to light people might just need a little old fashioned. steve takes in coulson is sentiment. int. underground lab day several soldiers under loki is mind control run around preparing to infiltrate whatever loki has planned. loki sits down watching selvig work with a cms device. loki meditates until ext. throne room night the scepter materializes him back into the throne room of the other fully armed in his horned helmet and armor. the other appears from the steps. the other the chitauri grow restless. loki let them go at themselves. i will lead them into glorious battle. the other battle against the meager might of earth loki glorious not lengthy. if your force is as formidable as you claim. the other you question us you question him he who put the scepter in your hand who gave you ancient knowledge and new purpose when you were cast out defeated loki i was a king the rightful king of asgard betrayed the other your ambition is little born of childish need. we look beyond the earth to greater worlds the tesseract will unveil. loki you don not have the tesseract yet. the other runs over to attack him but stops as loki points his scepter.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8buG-jTDZVtV"
      },
      "source": [
        "# Spliting data into lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzVv3LrjaPWc",
        "outputId": "70a30343-55b7-4ca6-c990-95422a6f1a6a"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWcOJYHtXDIE"
      },
      "source": [
        "split_data = []\r\n",
        "\r\n",
        "stopwords = nltk.corpus.stopwords.words(\"english\")\r\n",
        "\r\n",
        "for lines in data.split(\".\"):\r\n",
        "    tmp_line = []\r\n",
        "    for word in lines.strip().split(\" \"):\r\n",
        "        if word not in stopwords:\r\n",
        "            if len(word) > 0:\r\n",
        "                tmp_line.append(word)\r\n",
        "    if len(tmp_line) > 0:\r\n",
        "        split_data.append(tmp_line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx1pSIhcaBT1",
        "outputId": "1046bbe4-9aa7-4773-d228-2ff914a75448"
      },
      "source": [
        "split_data[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['txt',\n",
              " 'nikhilroxtomarnikhilroxtomar',\n",
              " 'add',\n",
              " 'files',\n",
              " 'via',\n",
              " 'uploadlatest',\n",
              " 'commit',\n",
              " 'seven',\n",
              " 'five',\n",
              " 'five',\n",
              " 'six',\n",
              " 'b',\n",
              " 'two',\n",
              " 'feb',\n",
              " 'nine',\n",
              " 'two',\n",
              " 'zero',\n",
              " 'one',\n",
              " 'nine',\n",
              " 'history',\n",
              " 'one',\n",
              " 'contributor',\n",
              " 'five',\n",
              " 'nine',\n",
              " 'three',\n",
              " 'two',\n",
              " 'lines',\n",
              " 'four',\n",
              " 'three',\n",
              " 'seven',\n",
              " 'nine',\n",
              " 'sloc',\n",
              " 'one',\n",
              " 'nine',\n",
              " 'two',\n",
              " 'kb',\n",
              " 'avengers',\n",
              " 'written',\n",
              " 'joss',\n",
              " 'whedon',\n",
              " 'came',\n",
              " 'day',\n",
              " 'day',\n",
              " 'unlike',\n",
              " 'earth',\n",
              " 'mightiest',\n",
              " 'heroes',\n",
              " 'heroines',\n",
              " 'found',\n",
              " 'united',\n",
              " 'common',\n",
              " 'threat']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Pp8M0sabs5d"
      },
      "source": [
        "# Preparing dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44q9c2nSaVmE"
      },
      "source": [
        "def prepare_dictionary(data):\r\n",
        "    idx = 0\r\n",
        "    word2idx = {}\r\n",
        "    idx2word = {}\r\n",
        "\r\n",
        "    for line in data:\r\n",
        "        for word in line:\r\n",
        "            if word not in word2idx.keys():\r\n",
        "                word2idx[word] = idx\r\n",
        "                idx2word[idx] = word\r\n",
        "                idx += 1\r\n",
        "    vocab_size = len(word2idx.keys())\r\n",
        "    return vocab_size, word2idx, idx2word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Pyo6F1QdZLL",
        "outputId": "c507b418-c468-4260-d7c7-d8dc97b862b4"
      },
      "source": [
        "\r\n",
        "vocab_size, word2idx, idx2word = prepare_dictionary(split_data)\r\n",
        "print(\"Vocab Size: \", vocab_size ) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab Size:  1343\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyMEphB3gaxr"
      },
      "source": [
        "# Preparing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-PyLIgugZq-"
      },
      "source": [
        "def prepare_dataset(data, word2idx, vocab_size, window=5):\r\n",
        "    X = []\r\n",
        "    Y = []\r\n",
        "\r\n",
        "    for line in data:\r\n",
        "        fn = window//2\r\n",
        "        line_len = len(line)\r\n",
        "\r\n",
        "        if line_len > window:\r\n",
        "            for i in range(line_len):\r\n",
        "                a = line[i]\r\n",
        "                b = []\r\n",
        "                for j in range(window):\r\n",
        "                    idx = i+j-fn\r\n",
        "                    if (idx != i) and (idx >= 0 and idx < line_len):\r\n",
        "                        x = word2idx[line[i]]\r\n",
        "                        y = word2idx[line[idx]]\r\n",
        "\r\n",
        "                        X.append(x)\r\n",
        "                        Y.append(y)\r\n",
        "    X = np.array(X)\r\n",
        "    Y = np.array(Y)\r\n",
        "    return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1P23TgLdoW4"
      },
      "source": [
        "X, Y = prepare_dataset(split_data, word2idx, vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hteqpvobds4J",
        "outputId": "6a6fdc82-bdac-499c-9597-959764933c6a"
      },
      "source": [
        "\r\n",
        "print(split_data[0])\r\n",
        "\r\n",
        "for i in range(10):\r\n",
        "    print(\"{:20s} - {:20s}\".format(idx2word[X[i]], idx2word[Y[i]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['skip', 'contentsearch', 'jump', 'to…pull', 'requestsissuesmarketplaceexplore', 'epraddh', 'nikhilroxtomar', 'word', 'two', 'vec', 'one', 'two', 'zero', 'codeissuespull', 'requestsactionsprojectswikisecurityinsightsword', 'two', 'vec', 'avengers', 'two', 'zero', 'one', 'two']\n",
            "skip                 - contentsearch       \n",
            "skip                 - jump                \n",
            "contentsearch        - skip                \n",
            "contentsearch        - jump                \n",
            "contentsearch        - to…pull             \n",
            "jump                 - skip                \n",
            "jump                 - contentsearch       \n",
            "jump                 - to…pull             \n",
            "jump                 - requestsissuesmarketplaceexplore\n",
            "to…pull              - contentsearch       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-oWYb6cmKn6"
      },
      "source": [
        "# Onehot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0pj5CFJiilS"
      },
      "source": [
        "def onehot_encoding(x, y):\r\n",
        "    X = tf.one_hot(x, vocab_size)\r\n",
        "    Y = tf.one_hot(y, vocab_size)\r\n",
        "    return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FoklSolmWPQ"
      },
      "source": [
        "# Generate dataset batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr1mn4cDDg0T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3JBltxTmVII"
      },
      "source": [
        "def batch_dataset(x, y, batch_size=1024, prefetch=2):\r\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\r\n",
        "    dataset = dataset.map(onehot_encoding)\r\n",
        "    dataset = dataset.batch(batch_size)\r\n",
        "    dataset = tf.data.Dataset.prefetch(dataset,2)\r\n",
        "    #itr = tf.compat.v1.data.make_initializable_iterator(dataset)\r\n",
        "    for element in dataset:\r\n",
        "      return  element"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEHS9NA2im5R"
      },
      "source": [
        "itr,data = batch_dataset(X, Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecx5hZGzm7Va"
      },
      "source": [
        "from tensorflow.python.framework.ops import disable_eager_execution\r\n",
        "\r\n",
        "disable_eager_execution()\r\n",
        "\r\n",
        "#x_inputs = tf.placeholder(tf.float32, shape=[None, vocab_size])\r\n",
        "x_inputs = tf.compat.v1.placeholder(shape=[None, vocab_size], dtype=tf.float32)\r\n",
        "#y_labels = tf.placeholder(tf.float32, shape=[None, vocab_size])\r\n",
        "y_labels = tf.compat.v1.placeholder(shape=[None, vocab_size], dtype=tf.float32)\r\n",
        "\r\n",
        "#global_step = tf.train.create_global_step()\r\n",
        "\r\n",
        "embed_dim = 32\r\n",
        "\r\n",
        "# hidden layer: which represents word vector eventually\r\n",
        "W1 = tf.Variable(tf.random.normal([vocab_size, embed_dim]))\r\n",
        "b1 = tf.Variable(tf.random.normal([embed_dim])) #bias\r\n",
        "hidden_representation = tf.add(tf.matmul(x_inputs,W1), b1)\r\n",
        "\r\n",
        "# output layer\r\n",
        "W2 = tf.Variable(tf.random.normal([embed_dim, vocab_size]))\r\n",
        "b2 = tf.Variable(tf.random.normal([vocab_size]))\r\n",
        "prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_representation, W2), b2))\r\n",
        "\r\n",
        "# loss function: cross entropy\r\n",
        "loss = tf.reduce_mean(-tf.reduce_sum(y_labels * tf.math.log(prediction), axis=[1]))\r\n",
        "\r\n",
        "# training operation\r\n",
        "#train_op = tf.optimizers.Adam().minimize(loss,var_list=[W2,b2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "49wLAFHfBeLg",
        "outputId": "45fac58d-bf9c-4515-919c-e19b3af743f5"
      },
      "source": [
        "sess = tf.compat.v1.Session()\r\n",
        "init = tf.compat.v1.global_variables_initializer()\r\n",
        "sess.run(init) #make sure you do this!\r\n",
        "# define the loss function:\r\n",
        "cross_entropy_loss = tf.math.reduce_mean(-tf.reduce_sum(y_labels * tf.math.log(prediction),axis=[1] ))\r\n",
        "# define the training step:\r\n",
        "train_step = tf.optimizers.SGD(0.1).minimize(cross_entropy_loss,var_list=(W2,b2 ))\r\n",
        "n_iters = 10000\r\n",
        "# train for n_iter iterations\r\n",
        "for _ in range(n_iters):\r\n",
        "    sess.run(train_step, feed_dict={x: x_train, y_label: y_train})\r\n",
        "    print('loss is : ', sess.run(cross_entropy_loss, feed_dict={x: x_train, y_label: y_train}))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-158-30c4044dd725>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcross_entropy_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_labels\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# define the training step:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb2\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mn_iters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# train for n_iter iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name)\u001b[0m\n\u001b[1;32m    373\u001b[0m     \"\"\"\n\u001b[1;32m    374\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[0;32m--> 375\u001b[0;31m         loss, var_list=var_list, grad_loss=grad_loss)\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss)\u001b[0m\n\u001b[1;32m    427\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m       \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m       \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTS9DHaofO0q"
      },
      "source": [
        "# https://github.com/nikhilroxtomar/Word2vec/blob/master/Skip_Gram_Word2Vec.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}