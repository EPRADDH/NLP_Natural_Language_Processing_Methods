{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNchSVIVycRIockmEE4ucZ4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EPRADDH/NLP_Natural_Language_Processing_Methods/blob/main/Topic_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVGIZjQDcugk"
      },
      "source": [
        "Topic modeling is a process of automatically identifying the topics present in a text corpus, it derives the hidden patterns among the words in the corpus in an unsupervised manner. Topics are defined as “a repeating pattern of co-occurring terms in a corpus”.\r\n",
        "\r\n",
        "\r\n",
        "Topic Models are very useful for the purpose for document clustering, organizing large blocks of textual data, information retrieval from unstructured text and feature selection\r\n",
        "\r\n",
        "There are many approaches for obtaining topics from a text such as – Term Frequency and Inverse Document Frequency. NonNegative Matrix Factorization techniques. Latent Dirichlet Allocation is the most popular topic modeling technique and Sometimes LDA can also be used as feature selection technique.\r\n",
        "# Latent Dirichlet Allocation for Topic Modeling\r\n",
        "\r\n",
        "Parameters of LDA\r\n",
        "\r\n",
        "Python Implementation\r\n",
        "\r\n",
        "Preparing documents\r\n",
        "\r\n",
        "Cleaning and Preprocessing\r\n",
        "\r\n",
        "Preparing document term matrix\r\n",
        "\r\n",
        "Running LDA model\r\n",
        "\r\n",
        "Results\r\n",
        "\r\n",
        "# Tips to improve results of topic modelling\r\n",
        "\r\n",
        "Frequency Filter\r\n",
        "\r\n",
        "Part of Speech Tag Filter\r\n",
        "\r\n",
        "Batch Wise LDA\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIHIu-D71qPI"
      },
      "source": [
        "#LDA\r\n",
        "here LDA assumes documents are produced from a mixture of topics.and those topics are generated based on words probabilty distribution .\r\n",
        "\r\n",
        "LDA is a matrix factorization technique. In vector space, any corpus (collection of documents) can be represented as a document-term matrix. The matrix shows a corpus of N documents D1, D2, D3 … Dn and vocabulary size of M words W1,W2 .. Wn\r\n",
        "and the value of  cell gives the frequency count of word Wj in Document Di.\r\n",
        "\r\n",
        "LDA converts this Document-Term Matrix into two lower dimensional matrices – M1 and M2.\r\n",
        "M1 is a document-topics matrix and M2 is a topic – terms matrix .\r\n",
        "\r\n",
        "these two matrices provides topic word and document topic distributions\r\n",
        "\r\n",
        "using matrices for every topic, two probabilities p1 and p2 are calculated\r\n",
        "\r\n",
        "1. p(topic t / document d)\r\n",
        "2. p(word w / topic t)\r\n",
        "\r\n",
        "\r\n",
        "#Parameters of LDA\r\n",
        "Alpha and Beta Hyperparameters – alpha represents document-topic density and Beta represents topic-word density. Higher the value of alpha, documents are composed of more topics and lower the value of alpha, documents contain fewer topics. On the other hand, higher the beta, topics are composed of a large number of words in the corpus, and with the lower value of beta, they are composed of few words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ug1H134FwIQ"
      },
      "source": [
        "# Preparing Documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcYbPnweciZz"
      },
      "source": [
        "doc1 = \"Sugar is bad to consume. My sister likes to have sugar, but not my father.\"\r\n",
        "doc2 = \"My father spends a lot of time driving my sister around to dance practice.\"\r\n",
        "doc3 = \"Doctors suggest that driving may cause increased stress and blood pressure.\"\r\n",
        "doc4 = \"Sometimes I feel pressure to perform well at school, but my father never seems to drive my sister to do better.\"\r\n",
        "doc5 = \"Health experts say that Sugar is not good for your lifestyle.\"\r\n",
        "\r\n",
        "# compile documents\r\n",
        "doc_complete = [doc1, doc2, doc3, doc4, doc5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_7JTwYRGHWf"
      },
      "source": [
        "# Cleaning and Preprocessing\r\n",
        "Cleaning is an important step before any text mining task, in this step, we will remove the punctuations, stopwords and normalize the corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CgxRSHRGQ5D",
        "outputId": "64a4020b-148b-473a-807c-0cdf32fafb3a"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUMsfY-MF0cW"
      },
      "source": [
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\r\n",
        "import string\r\n",
        "stop = set(stopwords.words('english'))\r\n",
        "exclude = set(string.punctuation)\r\n",
        "lemma = WordNetLemmatizer()\r\n",
        "def clean(doc):\r\n",
        "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\r\n",
        "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\r\n",
        "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\r\n",
        "    return normalized\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDwTBLaJGNIy"
      },
      "source": [
        "\r\n",
        "doc_clean = [clean(doc).split() for doc in doc_complete]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax5FtTlzGp-a",
        "outputId": "3d1be216-996f-49f2-bbcf-1a40bb6c9565"
      },
      "source": [
        "doc_clean"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['sugar', 'bad', 'consume', 'sister', 'like', 'sugar', 'father'],\n",
              " ['father',\n",
              "  'spends',\n",
              "  'lot',\n",
              "  'time',\n",
              "  'driving',\n",
              "  'sister',\n",
              "  'around',\n",
              "  'dance',\n",
              "  'practice'],\n",
              " ['doctor',\n",
              "  'suggest',\n",
              "  'driving',\n",
              "  'may',\n",
              "  'cause',\n",
              "  'increased',\n",
              "  'stress',\n",
              "  'blood',\n",
              "  'pressure'],\n",
              " ['sometimes',\n",
              "  'feel',\n",
              "  'pressure',\n",
              "  'perform',\n",
              "  'well',\n",
              "  'school',\n",
              "  'father',\n",
              "  'never',\n",
              "  'seems',\n",
              "  'drive',\n",
              "  'sister',\n",
              "  'better'],\n",
              " ['health', 'expert', 'say', 'sugar', 'good', 'lifestyle']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c6-1Nk3HlLm"
      },
      "source": [
        "#Preparing Document-Term Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-a5j91_GsX2"
      },
      "source": [
        "# Importing Gensim\r\n",
        "import gensim\r\n",
        "from gensim import corpora\r\n",
        "\r\n",
        "# Creating the term dictionary of our courpus, where every unique term is assigned an index. \r\n",
        "\r\n",
        "dictionary = corpora.Dictionary(doc_clean)\r\n",
        "\r\n",
        "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\r\n",
        "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bmXD_x2H7a-"
      },
      "source": [
        "#Running LDA Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CSIO3FOHrMa"
      },
      "source": [
        "#Creating the object for LDA model using gensim library\r\n",
        "Lda = gensim.models.ldamodel.LdaModel\r\n",
        "\r\n",
        "# Running and Trainign LDA model on the document term matrix.\r\n",
        "ldamodel = Lda(doc_term_matrix, num_topics=3, id2word = dictionary, passes=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkvWTaIJIG8d",
        "outputId": "7a67956f-2201-402f-b205-129f2a225e73"
      },
      "source": [
        "print(ldamodel.print_topics(num_topics=3, num_words=3))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, '0.072*\"sister\" + 0.072*\"father\" + 0.041*\"drive\"'), (1, '0.135*\"sugar\" + 0.054*\"like\" + 0.054*\"consume\"'), (2, '0.065*\"driving\" + 0.065*\"pressure\" + 0.064*\"stress\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZ77Xo-YIV9S"
      },
      "source": [
        "Each line is a topic with individual topic terms and weights. Topic1 can be termed as Bad Health, and Topic3 can be termed as Family"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP8qXIdxIOtF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}