{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CBOW_Word2Vec_.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN/x2qeePYICokhjsqNtK7V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EPRADDH/NLP_Natural_Language_Processing_Methods/blob/main/CBOW_Word2Vec_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9Az7AkNtrGR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l_WMWjpgtVL"
      },
      "source": [
        "# Word2vec \n",
        "word2vwc is basically a word embedding technique that is used to convert the words in the dataset to vectors so that the machine understands. Each unique word in your data is assigned to a vector and these vectors vary in dimensions depending on the length of the word.\n",
        "\n",
        "This model was created by Google in 2013 and is a predictive deep learning based model to compute and generate high quality, distributed and continuous dense vector representations of words, which capture contextual and semantic similarity\n",
        "\n",
        "t is a shallow two-layered neural network.where there is input one hidden layer and output.\n",
        "\n",
        "difference between shallow and deep neural network:\n",
        "\n",
        "The shallow neural network consists of the only a hidden layer between input and output whereas deep neural network contains multiple hidden layers between input and output. Input is subjected to nodes whereas the hidden layer, as well as the output layer, contains neurons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXjDAU_jZJEE"
      },
      "source": [
        "words2vec know as neural word embedding it has 200 -400 dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VcyRssFMliF"
      },
      "source": [
        "#Word2VecCustomModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ChBvWcMY7Sj",
        "outputId": "8543afdf-0b8c-418f-a659-65fc3f55ec4e"
      },
      "source": [
        "import gensim.downloader as api\n",
        "wv = api.load('word2vec-google-news-300')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[================================================--] 97.1% 1614.2/1662.8MB downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCOETyyKMoHG",
        "outputId": "2f8c10ff-0fd4-41c2-ffe8-456eb5a06fd3"
      },
      "source": [
        "for i, word in enumerate(wv.vocab):\n",
        "    if i == 10:\n",
        "        break\n",
        "    print(word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "</s>\n",
            "in\n",
            "for\n",
            "that\n",
            "is\n",
            "on\n",
            "##\n",
            "The\n",
            "with\n",
            "said\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c68exwblMoLW",
        "outputId": "5094a282-8767-4495-f7bd-01f4d3a4a23a"
      },
      "source": [
        "\n",
        "vec_king = wv['king']\n",
        "print(vec_king)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1.25976562e-01  2.97851562e-02  8.60595703e-03  1.39648438e-01\n",
            " -2.56347656e-02 -3.61328125e-02  1.11816406e-01 -1.98242188e-01\n",
            "  5.12695312e-02  3.63281250e-01 -2.42187500e-01 -3.02734375e-01\n",
            " -1.77734375e-01 -2.49023438e-02 -1.67968750e-01 -1.69921875e-01\n",
            "  3.46679688e-02  5.21850586e-03  4.63867188e-02  1.28906250e-01\n",
            "  1.36718750e-01  1.12792969e-01  5.95703125e-02  1.36718750e-01\n",
            "  1.01074219e-01 -1.76757812e-01 -2.51953125e-01  5.98144531e-02\n",
            "  3.41796875e-01 -3.11279297e-02  1.04492188e-01  6.17675781e-02\n",
            "  1.24511719e-01  4.00390625e-01 -3.22265625e-01  8.39843750e-02\n",
            "  3.90625000e-02  5.85937500e-03  7.03125000e-02  1.72851562e-01\n",
            "  1.38671875e-01 -2.31445312e-01  2.83203125e-01  1.42578125e-01\n",
            "  3.41796875e-01 -2.39257812e-02 -1.09863281e-01  3.32031250e-02\n",
            " -5.46875000e-02  1.53198242e-02 -1.62109375e-01  1.58203125e-01\n",
            " -2.59765625e-01  2.01416016e-02 -1.63085938e-01  1.35803223e-03\n",
            " -1.44531250e-01 -5.68847656e-02  4.29687500e-02 -2.46582031e-02\n",
            "  1.85546875e-01  4.47265625e-01  9.58251953e-03  1.31835938e-01\n",
            "  9.86328125e-02 -1.85546875e-01 -1.00097656e-01 -1.33789062e-01\n",
            " -1.25000000e-01  2.83203125e-01  1.23046875e-01  5.32226562e-02\n",
            " -1.77734375e-01  8.59375000e-02 -2.18505859e-02  2.05078125e-02\n",
            " -1.39648438e-01  2.51464844e-02  1.38671875e-01 -1.05468750e-01\n",
            "  1.38671875e-01  8.88671875e-02 -7.51953125e-02 -2.13623047e-02\n",
            "  1.72851562e-01  4.63867188e-02 -2.65625000e-01  8.91113281e-03\n",
            "  1.49414062e-01  3.78417969e-02  2.38281250e-01 -1.24511719e-01\n",
            " -2.17773438e-01 -1.81640625e-01  2.97851562e-02  5.71289062e-02\n",
            " -2.89306641e-02  1.24511719e-02  9.66796875e-02 -2.31445312e-01\n",
            "  5.81054688e-02  6.68945312e-02  7.08007812e-02 -3.08593750e-01\n",
            " -2.14843750e-01  1.45507812e-01 -4.27734375e-01 -9.39941406e-03\n",
            "  1.54296875e-01 -7.66601562e-02  2.89062500e-01  2.77343750e-01\n",
            " -4.86373901e-04 -1.36718750e-01  3.24218750e-01 -2.46093750e-01\n",
            " -3.03649902e-03 -2.11914062e-01  1.25000000e-01  2.69531250e-01\n",
            "  2.04101562e-01  8.25195312e-02 -2.01171875e-01 -1.60156250e-01\n",
            " -3.78417969e-02 -1.20117188e-01  1.15234375e-01 -4.10156250e-02\n",
            " -3.95507812e-02 -8.98437500e-02  6.34765625e-03  2.03125000e-01\n",
            "  1.86523438e-01  2.73437500e-01  6.29882812e-02  1.41601562e-01\n",
            " -9.81445312e-02  1.38671875e-01  1.82617188e-01  1.73828125e-01\n",
            "  1.73828125e-01 -2.37304688e-01  1.78710938e-01  6.34765625e-02\n",
            "  2.36328125e-01 -2.08984375e-01  8.74023438e-02 -1.66015625e-01\n",
            " -7.91015625e-02  2.43164062e-01 -8.88671875e-02  1.26953125e-01\n",
            " -2.16796875e-01 -1.73828125e-01 -3.59375000e-01 -8.25195312e-02\n",
            " -6.49414062e-02  5.07812500e-02  1.35742188e-01 -7.47070312e-02\n",
            " -1.64062500e-01  1.15356445e-02  4.45312500e-01 -2.15820312e-01\n",
            " -1.11328125e-01 -1.92382812e-01  1.70898438e-01 -1.25000000e-01\n",
            "  2.65502930e-03  1.92382812e-01 -1.74804688e-01  1.39648438e-01\n",
            "  2.92968750e-01  1.13281250e-01  5.95703125e-02 -6.39648438e-02\n",
            "  9.96093750e-02 -2.72216797e-02  1.96533203e-02  4.27246094e-02\n",
            " -2.46093750e-01  6.39648438e-02 -2.25585938e-01 -1.68945312e-01\n",
            "  2.89916992e-03  8.20312500e-02  3.41796875e-01  4.32128906e-02\n",
            "  1.32812500e-01  1.42578125e-01  7.61718750e-02  5.98144531e-02\n",
            " -1.19140625e-01  2.74658203e-03 -6.29882812e-02 -2.72216797e-02\n",
            " -4.82177734e-03 -8.20312500e-02 -2.49023438e-02 -4.00390625e-01\n",
            " -1.06933594e-01  4.24804688e-02  7.76367188e-02 -1.16699219e-01\n",
            "  7.37304688e-02 -9.22851562e-02  1.07910156e-01  1.58203125e-01\n",
            "  4.24804688e-02  1.26953125e-01  3.61328125e-02  2.67578125e-01\n",
            " -1.01074219e-01 -3.02734375e-01 -5.76171875e-02  5.05371094e-02\n",
            "  5.26428223e-04 -2.07031250e-01 -1.38671875e-01 -8.97216797e-03\n",
            " -2.78320312e-02 -1.41601562e-01  2.07031250e-01 -1.58203125e-01\n",
            "  1.27929688e-01  1.49414062e-01 -2.24609375e-02 -8.44726562e-02\n",
            "  1.22558594e-01  2.15820312e-01 -2.13867188e-01 -3.12500000e-01\n",
            " -3.73046875e-01  4.08935547e-03  1.07421875e-01  1.06933594e-01\n",
            "  7.32421875e-02  8.97216797e-03 -3.88183594e-02 -1.29882812e-01\n",
            "  1.49414062e-01 -2.14843750e-01 -1.83868408e-03  9.91210938e-02\n",
            "  1.57226562e-01 -1.14257812e-01 -2.05078125e-01  9.91210938e-02\n",
            "  3.69140625e-01 -1.97265625e-01  3.54003906e-02  1.09375000e-01\n",
            "  1.31835938e-01  1.66992188e-01  2.35351562e-01  1.04980469e-01\n",
            " -4.96093750e-01 -1.64062500e-01 -1.56250000e-01 -5.22460938e-02\n",
            "  1.03027344e-01  2.43164062e-01 -1.88476562e-01  5.07812500e-02\n",
            " -9.37500000e-02 -6.68945312e-02  2.27050781e-02  7.61718750e-02\n",
            "  2.89062500e-01  3.10546875e-01 -5.37109375e-02  2.28515625e-01\n",
            "  2.51464844e-02  6.78710938e-02 -1.21093750e-01 -2.15820312e-01\n",
            " -2.73437500e-01 -3.07617188e-02 -3.37890625e-01  1.53320312e-01\n",
            "  2.33398438e-01 -2.08007812e-01  3.73046875e-01  8.20312500e-02\n",
            "  2.51953125e-01 -7.61718750e-02 -4.66308594e-02 -2.23388672e-02\n",
            "  2.99072266e-02 -5.93261719e-02 -4.66918945e-03 -2.44140625e-01\n",
            " -2.09960938e-01 -2.87109375e-01 -4.54101562e-02 -1.77734375e-01\n",
            " -2.79296875e-01 -8.59375000e-02  9.13085938e-02  2.51953125e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fqn1Oq_zMoTp",
        "outputId": "dafcac82-416a-4c0b-9476-dc7f277fd4bb"
      },
      "source": [
        "pairs = [\n",
        "    ('car', 'minivan'),   # a minivan is a kind of car\n",
        "    ('car', 'bicycle'),   # still a wheeled vehicle\n",
        "    ('car', 'airplane'),  # ok, no wheels, but still a vehicle\n",
        "    ('car', 'cereal'),    # ... and so on\n",
        "    ('car', 'communism'),\n",
        "]\n",
        "for w1, w2 in pairs:\n",
        "    print('%r\\t%r\\t%.2f' % (w1, w2, wv.similarity(w1, w2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'car'\t'minivan'\t0.69\n",
            "'car'\t'bicycle'\t0.54\n",
            "'car'\t'airplane'\t0.42\n",
            "'car'\t'cereal'\t0.14\n",
            "'car'\t'communism'\t0.06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v5RcFAWM_k8",
        "outputId": "8cd1591e-582b-43a9-a95d-55e33236aeaa"
      },
      "source": [
        "print(wv.most_similar(positive=['car', 'minivan'], topn=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[('SUV', 0.853219211101532), ('vehicle', 0.8175784349441528), ('pickup_truck', 0.7763689160346985), ('Jeep', 0.7567334175109863), ('Ford_Explorer', 0.756571888923645)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q02xjBXM_wp",
        "outputId": "8e5cd657-e405-4145-85e3-7489992a0e41"
      },
      "source": [
        "print(wv.doesnt_match(['fire', 'water', 'land', 'sea', 'air', 'car']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "car\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I8ZTyy5R8I2"
      },
      "source": [
        "The dataset is from Amazon Review Data (2018) https://nijianmo.github.io/amazon/index.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-kBtsUrM_8z"
      },
      "source": [
        "import json\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AbDh0j40A0W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDbZgKET4b-C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2Qpx6LX4jrI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x5bax894k6v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVHFSQqeyOBp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBnauEKaLk3h"
      },
      "source": [
        "import collections\n",
        "import math\n",
        "import os\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_0ePHfsJqzS"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from six.moves import urllib\n",
        "import tensorflow as tf\n",
        "\n",
        "# Step 1: Download the data.\n",
        "url = 'http://mattmahoney.net/dc/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGv9iY_6JSDj"
      },
      "source": [
        "def maybe_download(filename, expected_bytes):\n",
        "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
        "  if not os.path.exists(filename):\n",
        "    filename, _ = urllib.request.urlretrieve(url + filename, filename)\n",
        "  statinfo = os.stat(filename)\n",
        "  if statinfo.st_size == expected_bytes:\n",
        "    print('Found and verified', filename)\n",
        "  else:\n",
        "    print(statinfo.st_size)\n",
        "    raise Exception(\n",
        "        'Failed to verify ' + filename + '. Can you get to it with a browser?')\n",
        "  return filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFMdheoQJSPd",
        "outputId": "9a90fef9-6153-4eb1-ef0a-5d47b24c61b8"
      },
      "source": [
        "filename = maybe_download('text8.zip', 31344016)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found and verified text8.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiTAz7zhJSTF"
      },
      "source": [
        "# Read the data into a list of strings.\n",
        "import zipfile\n",
        "def read_data(filename):\n",
        "  \"\"\"Extract the first file enclosed in a zip file as a list of words.\"\"\"\n",
        "  with zipfile.ZipFile(filename) as f:\n",
        "    data = tf.compat.as_str(f.read(f.namelist()[0])).split()\n",
        "  return data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4ij2kAHKjQV",
        "outputId": "700ec32f-6071-4c8e-a593-cbd57828cbb8"
      },
      "source": [
        "vocabulary = read_data(filename)\n",
        "print('Data size', len(vocabulary))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data size 17005207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rdoUBeZKjax"
      },
      "source": [
        "# Step 2: Build the dictionary and replace rare words with UNK token.\n",
        "vocabulary_size = 50000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFPJus3MKjiQ"
      },
      "source": [
        "def build_dataset(words, n_words):\n",
        "  \"\"\"Process raw inputs into a dataset.\"\"\"\n",
        "  count = [['UNK', -1]]\n",
        "  count.extend(collections.Counter(words).most_common(n_words - 1))\n",
        "  dictionary = dict()\n",
        "  for word, _ in count:\n",
        "    dictionary[word] = len(dictionary)\n",
        "  data = list()\n",
        "  unk_count = 0\n",
        "  for word in words:\n",
        "    if word in dictionary:\n",
        "      index = dictionary[word]\n",
        "    else:\n",
        "      index = 0  # dictionary['UNK']\n",
        "      unk_count += 1\n",
        "    data.append(index)\n",
        "  count[0][1] = unk_count\n",
        "  reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
        "  return data, count, dictionary, reversed_dictionary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KGCbLm4LT2u"
      },
      "source": [
        "data, count, dictionary, reverse_dictionary = build_dataset(vocabulary,\n",
        "                                                            vocabulary_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2gm98UhLUGb",
        "outputId": "766f2056-0c88-49f5-ca42-523262b70285"
      },
      "source": [
        "print('Most common words (+UNK)', count[:5])\n",
        "print('Sample data', data[:10], [reverse_dictionary[i] for i in data[:10]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most common words (+UNK) [['UNK', 418391], ('the', 1061396), ('of', 593677), ('and', 416629), ('one', 411764)]\n",
            "Sample data [5234, 3081, 12, 6, 195, 2, 3134, 46, 59, 156] ['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OupgfLPMl-v"
      },
      "source": [
        "data_index = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hZxwTROMmMJ"
      },
      "source": [
        "# Step 3: Function to generate a training batch for the skip-gram model.\n",
        "def generate_batch(batch_size, num_skips, skip_window):\n",
        "  global data_index\n",
        "  assert batch_size % num_skips == 0\n",
        "  assert num_skips <= 2 * skip_window\n",
        "  batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
        "  labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
        "  span = 2 * skip_window + 1  # [ skip_window target skip_window ]\n",
        "  buffer = collections.deque(maxlen=span)\n",
        "  for _ in range(span):\n",
        "    buffer.append(data[data_index])\n",
        "    data_index = (data_index + 1) % len(data)\n",
        "  for i in range(batch_size // num_skips):\n",
        "    target = skip_window  # target label at the center of the buffer\n",
        "    targets_to_avoid = [skip_window]\n",
        "    for j in range(num_skips):\n",
        "      while target in targets_to_avoid:\n",
        "        target = random.randint(0, span - 1)\n",
        "      targets_to_avoid.append(target)\n",
        "      batch[i * num_skips + j] = buffer[skip_window]\n",
        "      labels[i * num_skips + j, 0] = buffer[target]\n",
        "    buffer.append(data[data_index])\n",
        "    data_index = (data_index + 1) % len(data)\n",
        "  # Backtrack a little bit to avoid skipping words in the end of a batch\n",
        "  data_index = (data_index + len(data) - span) % len(data)\n",
        "  return batch, labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KMpMoyJMma_",
        "outputId": "ee3772c7-2867-47db-c06a-b8f383199df0"
      },
      "source": [
        "batch, labels = generate_batch(batch_size=8, num_skips=2, skip_window=1)\n",
        "for i in range(8):\n",
        "  print(batch[i], reverse_dictionary[batch[i]],\n",
        "        '->', labels[i, 0], reverse_dictionary[labels[i, 0]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3081 originated -> 12 as\n",
            "3081 originated -> 5234 anarchism\n",
            "12 as -> 6 a\n",
            "12 as -> 3081 originated\n",
            "6 a -> 195 term\n",
            "6 a -> 12 as\n",
            "195 term -> 2 of\n",
            "195 term -> 6 a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvRgyIe0N87F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxmtJ3j2O3b0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn1dxhomO3rb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCKih5Zmp-ze"
      },
      "source": [
        "# [Continuous Bag of Words (CBOW) Model](https://thinkinfi.com/continuous-bag-of-words-cbow-single-word-model-how-it-works/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH6mbrnhqi0P"
      },
      "source": [
        "The CBOW model architecture tries to predict the current target word (the center word) based on the source context words (surrounding words).\n",
        "\n",
        "Considering a simple sentence, “the quick brown fox jumps over the lazy dog”, \n",
        "\n",
        "this can be pairs of (context_window, target_word) where if we consider a context window of size 2, \n",
        "\n",
        "we have examples like ([quick, fox], brown), ([the, brown], quick), ([the, dog], lazy) and so on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmx2snFz9TZx"
      },
      "source": [
        "In the CBOW model, the distributed representations of context (or surrounding words) are combined to predict the word in the middle. While in the Skip-gram model, the distributed representation of the input word is used to predict the context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkbXrlvRZ7UC"
      },
      "source": [
        "The Continuous Bag-of-Words model (CBOW) is frequently used in NLP deep learning. It is a model that tries to predict words given the context of a few words before and a few words after the target word\n",
        "\n",
        "Typcially, CBOW is used to quickly train word embeddings, and these embeddings are used to initialize the embeddings of some more complicated model. Usually, this is referred to as pretraining embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7ZBOPyWcvr0"
      },
      "source": [
        "The CBOW model is as follows. Given a target word wi and an N context window on each side, wi−1,…,wi−N and wi+1,…,wi+N, referring to all context words collectively as C, \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HK9Jf29gzMO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBp6J39jvRLe"
      },
      "source": [
        "use robust frameworks which have the Word2Vec model like gensim, let’s try and implement this from scratch to gain some perspective on how things really work behind the scenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ1r39OZveFa"
      },
      "source": [
        "# Build the corpus vocabulary\n",
        "To start off, we will first build our corpus vocabulary where we extract out each unique word from our vocabulary and map a unique numeric identifier to it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwJEML7Bxksz",
        "outputId": "d4e29849-0aa9-43d6-9b61-a301684d24f8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igiTpSMwvSJn"
      },
      "source": [
        "from keras.preprocessing import text\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "from keras.preprocessing.text import text_to_word_sequence\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WrcRmq_GTyB"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnlRRE7QyEIU"
      },
      "source": [
        "data=open('/content/drive/MyDrive/NLP-Natural-Language-Processing-Methods/corona.txt','r',encoding='cp1252')\n",
        "norm_bible = [text for text in data if text.count(' ') >= 2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAkYoUESHbyX",
        "outputId": "fa4978c6-60eb-4cfd-d996-6f67ba3ae4da"
      },
      "source": [
        "norm_bible"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The speed of transmission is an important point of difference between the two viruses. Influenza has a shorter median incubation period (the time from infection to appearance of symptoms) and a shorter serial interval (the time between successive cases) than COVID-19 virus. The serial interval for COVID-19 virus is estimated to be 5-6 days, while for influenza virus, the serial interval is 3 days. This means that influenza can spread faster than COVID-19. \\n',\n",
              " 'Further, transmission in the first 3-5 days of illness, or potentially pre-symptomatic transmission –transmission of the virus before the appearance of symptoms – is a major driver of transmission for influenza. In contrast, while we are learning that there are people who can shed COVID-19 virus 24-48 hours prior to symptom onset, at present, this does not appear to be a major driver of transmission. \\n',\n",
              " 'The reproductive number – the number of secondary infections generated from one infected individual – is understood to be between 2 and 2.5 for COVID-19 virus, higher than for influenza. However, estimates for both COVID-19 and influenza viruses are very context and time-specific, making direct comparisons more difficult.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXxlEw5Cvuuq"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(norm_bible)\n",
        "word2id = tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lObarQvKH6iF",
        "outputId": "c506c75f-89ba-4a28-a9c0-b2b4e828ca8a"
      },
      "source": [
        "word2id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'19': 5,\n",
              " '2': 37,\n",
              " '24': 72,\n",
              " '3': 29,\n",
              " '48': 73,\n",
              " '5': 19,\n",
              " '6': 52,\n",
              " 'a': 11,\n",
              " 'an': 39,\n",
              " 'and': 12,\n",
              " 'appear': 82,\n",
              " 'appearance': 26,\n",
              " 'are': 22,\n",
              " 'at': 78,\n",
              " 'be': 18,\n",
              " 'before': 64,\n",
              " 'between': 13,\n",
              " 'both': 94,\n",
              " 'can': 32,\n",
              " 'cases': 50,\n",
              " 'comparisons': 100,\n",
              " 'context': 96,\n",
              " 'contrast': 65,\n",
              " 'covid': 4,\n",
              " 'days': 20,\n",
              " 'difference': 42,\n",
              " 'difficult': 102,\n",
              " 'direct': 99,\n",
              " 'does': 80,\n",
              " 'driver': 35,\n",
              " 'estimated': 51,\n",
              " 'estimates': 93,\n",
              " 'faster': 55,\n",
              " 'first': 57,\n",
              " 'for': 7,\n",
              " 'from': 25,\n",
              " 'further': 56,\n",
              " 'generated': 86,\n",
              " 'has': 44,\n",
              " 'higher': 91,\n",
              " 'hours': 74,\n",
              " 'however': 92,\n",
              " 'illness': 58,\n",
              " 'important': 40,\n",
              " 'in': 33,\n",
              " 'incubation': 46,\n",
              " 'individual': 89,\n",
              " 'infected': 88,\n",
              " 'infection': 48,\n",
              " 'infections': 85,\n",
              " 'influenza': 3,\n",
              " 'interval': 16,\n",
              " 'is': 9,\n",
              " 'learning': 67,\n",
              " 'major': 34,\n",
              " 'making': 98,\n",
              " 'means': 53,\n",
              " 'median': 45,\n",
              " 'more': 101,\n",
              " 'not': 81,\n",
              " 'number': 36,\n",
              " 'of': 2,\n",
              " 'one': 87,\n",
              " 'onset': 77,\n",
              " 'or': 59,\n",
              " 'people': 69,\n",
              " 'period': 47,\n",
              " 'point': 41,\n",
              " 'potentially': 60,\n",
              " 'pre': 61,\n",
              " 'present': 79,\n",
              " 'prior': 75,\n",
              " 'reproductive': 83,\n",
              " 'secondary': 84,\n",
              " 'serial': 15,\n",
              " 'shed': 71,\n",
              " 'shorter': 24,\n",
              " 'specific': 97,\n",
              " 'speed': 38,\n",
              " 'spread': 54,\n",
              " 'successive': 49,\n",
              " 'symptom': 76,\n",
              " 'symptomatic': 62,\n",
              " 'symptoms': 27,\n",
              " 'than': 17,\n",
              " 'that': 31,\n",
              " 'the': 1,\n",
              " 'there': 68,\n",
              " 'this': 30,\n",
              " 'time': 14,\n",
              " 'to': 10,\n",
              " 'transmission': 8,\n",
              " 'two': 43,\n",
              " 'understood': 90,\n",
              " 'very': 95,\n",
              " 'virus': 6,\n",
              " 'viruses': 23,\n",
              " 'we': 66,\n",
              " 'while': 28,\n",
              " 'who': 70,\n",
              " '–': 21,\n",
              " '–transmission': 63}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnIn5UR0x1qZ"
      },
      "source": [
        "# build vocabulary of unique words\n",
        "word2id['PAD'] = 0\n",
        "id2word = {v:k for k, v in word2id.items()}\n",
        "wids = [[word2id[w] for w in text_to_word_sequence(doc)] for doc in norm_bible]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nkc5izYaviK1",
        "outputId": "75550c07-8501-4ad7-87ef-cc94621ac567"
      },
      "source": [
        "id2word"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'PAD',\n",
              " 1: 'the',\n",
              " 2: 'of',\n",
              " 3: 'influenza',\n",
              " 4: 'covid',\n",
              " 5: '19',\n",
              " 6: 'virus',\n",
              " 7: 'for',\n",
              " 8: 'transmission',\n",
              " 9: 'is',\n",
              " 10: 'to',\n",
              " 11: 'a',\n",
              " 12: 'and',\n",
              " 13: 'between',\n",
              " 14: 'time',\n",
              " 15: 'serial',\n",
              " 16: 'interval',\n",
              " 17: 'than',\n",
              " 18: 'be',\n",
              " 19: '5',\n",
              " 20: 'days',\n",
              " 21: '–',\n",
              " 22: 'are',\n",
              " 23: 'viruses',\n",
              " 24: 'shorter',\n",
              " 25: 'from',\n",
              " 26: 'appearance',\n",
              " 27: 'symptoms',\n",
              " 28: 'while',\n",
              " 29: '3',\n",
              " 30: 'this',\n",
              " 31: 'that',\n",
              " 32: 'can',\n",
              " 33: 'in',\n",
              " 34: 'major',\n",
              " 35: 'driver',\n",
              " 36: 'number',\n",
              " 37: '2',\n",
              " 38: 'speed',\n",
              " 39: 'an',\n",
              " 40: 'important',\n",
              " 41: 'point',\n",
              " 42: 'difference',\n",
              " 43: 'two',\n",
              " 44: 'has',\n",
              " 45: 'median',\n",
              " 46: 'incubation',\n",
              " 47: 'period',\n",
              " 48: 'infection',\n",
              " 49: 'successive',\n",
              " 50: 'cases',\n",
              " 51: 'estimated',\n",
              " 52: '6',\n",
              " 53: 'means',\n",
              " 54: 'spread',\n",
              " 55: 'faster',\n",
              " 56: 'further',\n",
              " 57: 'first',\n",
              " 58: 'illness',\n",
              " 59: 'or',\n",
              " 60: 'potentially',\n",
              " 61: 'pre',\n",
              " 62: 'symptomatic',\n",
              " 63: '–transmission',\n",
              " 64: 'before',\n",
              " 65: 'contrast',\n",
              " 66: 'we',\n",
              " 67: 'learning',\n",
              " 68: 'there',\n",
              " 69: 'people',\n",
              " 70: 'who',\n",
              " 71: 'shed',\n",
              " 72: '24',\n",
              " 73: '48',\n",
              " 74: 'hours',\n",
              " 75: 'prior',\n",
              " 76: 'symptom',\n",
              " 77: 'onset',\n",
              " 78: 'at',\n",
              " 79: 'present',\n",
              " 80: 'does',\n",
              " 81: 'not',\n",
              " 82: 'appear',\n",
              " 83: 'reproductive',\n",
              " 84: 'secondary',\n",
              " 85: 'infections',\n",
              " 86: 'generated',\n",
              " 87: 'one',\n",
              " 88: 'infected',\n",
              " 89: 'individual',\n",
              " 90: 'understood',\n",
              " 91: 'higher',\n",
              " 92: 'however',\n",
              " 93: 'estimates',\n",
              " 94: 'both',\n",
              " 95: 'very',\n",
              " 96: 'context',\n",
              " 97: 'specific',\n",
              " 98: 'making',\n",
              " 99: 'direct',\n",
              " 100: 'comparisons',\n",
              " 101: 'more',\n",
              " 102: 'difficult'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8HtaCYXKa6d",
        "outputId": "7e36524c-9d75-4068-ce86-d3ed0facf144"
      },
      "source": [
        "wids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1,\n",
              "  38,\n",
              "  2,\n",
              "  8,\n",
              "  9,\n",
              "  39,\n",
              "  40,\n",
              "  41,\n",
              "  2,\n",
              "  42,\n",
              "  13,\n",
              "  1,\n",
              "  43,\n",
              "  23,\n",
              "  3,\n",
              "  44,\n",
              "  11,\n",
              "  24,\n",
              "  45,\n",
              "  46,\n",
              "  47,\n",
              "  1,\n",
              "  14,\n",
              "  25,\n",
              "  48,\n",
              "  10,\n",
              "  26,\n",
              "  2,\n",
              "  27,\n",
              "  12,\n",
              "  11,\n",
              "  24,\n",
              "  15,\n",
              "  16,\n",
              "  1,\n",
              "  14,\n",
              "  13,\n",
              "  49,\n",
              "  50,\n",
              "  17,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  1,\n",
              "  15,\n",
              "  16,\n",
              "  7,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  9,\n",
              "  51,\n",
              "  10,\n",
              "  18,\n",
              "  19,\n",
              "  52,\n",
              "  20,\n",
              "  28,\n",
              "  7,\n",
              "  3,\n",
              "  6,\n",
              "  1,\n",
              "  15,\n",
              "  16,\n",
              "  9,\n",
              "  29,\n",
              "  20,\n",
              "  30,\n",
              "  53,\n",
              "  31,\n",
              "  3,\n",
              "  32,\n",
              "  54,\n",
              "  55,\n",
              "  17,\n",
              "  4,\n",
              "  5],\n",
              " [56,\n",
              "  8,\n",
              "  33,\n",
              "  1,\n",
              "  57,\n",
              "  29,\n",
              "  19,\n",
              "  20,\n",
              "  2,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  62,\n",
              "  8,\n",
              "  63,\n",
              "  2,\n",
              "  1,\n",
              "  6,\n",
              "  64,\n",
              "  1,\n",
              "  26,\n",
              "  2,\n",
              "  27,\n",
              "  21,\n",
              "  9,\n",
              "  11,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  8,\n",
              "  7,\n",
              "  3,\n",
              "  33,\n",
              "  65,\n",
              "  28,\n",
              "  66,\n",
              "  22,\n",
              "  67,\n",
              "  31,\n",
              "  68,\n",
              "  22,\n",
              "  69,\n",
              "  70,\n",
              "  32,\n",
              "  71,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  72,\n",
              "  73,\n",
              "  74,\n",
              "  75,\n",
              "  10,\n",
              "  76,\n",
              "  77,\n",
              "  78,\n",
              "  79,\n",
              "  30,\n",
              "  80,\n",
              "  81,\n",
              "  82,\n",
              "  10,\n",
              "  18,\n",
              "  11,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  8],\n",
              " [1,\n",
              "  83,\n",
              "  36,\n",
              "  21,\n",
              "  1,\n",
              "  36,\n",
              "  2,\n",
              "  84,\n",
              "  85,\n",
              "  86,\n",
              "  25,\n",
              "  87,\n",
              "  88,\n",
              "  89,\n",
              "  21,\n",
              "  9,\n",
              "  90,\n",
              "  10,\n",
              "  18,\n",
              "  13,\n",
              "  37,\n",
              "  12,\n",
              "  37,\n",
              "  19,\n",
              "  7,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  91,\n",
              "  17,\n",
              "  7,\n",
              "  3,\n",
              "  92,\n",
              "  93,\n",
              "  7,\n",
              "  94,\n",
              "  4,\n",
              "  5,\n",
              "  12,\n",
              "  3,\n",
              "  23,\n",
              "  22,\n",
              "  95,\n",
              "  96,\n",
              "  12,\n",
              "  14,\n",
              "  97,\n",
              "  98,\n",
              "  99,\n",
              "  100,\n",
              "  101,\n",
              "  102]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeMn24Ntx5JA"
      },
      "source": [
        "vocab_size = len(word2id)\n",
        "embed_size = 100\n",
        "window_size = 2 # context window size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyg8ybL0x6P6",
        "outputId": "38c68013-1b5b-4a02-c30e-3055d6be287b"
      },
      "source": [
        "print('Vocabulary Size:', vocab_size)\n",
        "print('Vocabulary Sample:', list(word2id.items())[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 103\n",
            "Vocabulary Sample: [('the', 1), ('of', 2), ('influenza', 3), ('covid', 4), ('19', 5), ('virus', 6), ('for', 7), ('transmission', 8), ('is', 9), ('to', 10)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f-gWojMRiXN"
      },
      "source": [
        "#Build a CBOW (context, target) generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BDsWeFgLnbZ"
      },
      "source": [
        "def generate_context_word_pairs(corpus, window_size, vocab_size):\n",
        "    context_length = window_size*2\n",
        "    for words in corpus:\n",
        "        sentence_length = len(words)\n",
        "        for index, word in enumerate(words):\n",
        "            context_words = []\n",
        "            label_word   = []            \n",
        "            start = index - window_size\n",
        "            end = index + window_size + 1\n",
        "            \n",
        "            context_words.append([words[i] \n",
        "                                 for i in range(start, end) \n",
        "                                 if 0 <= i < sentence_length \n",
        "                                 and i != index])\n",
        "            label_word.append(word)\n",
        "\n",
        "            x = sequence.pad_sequences(context_words, maxlen=context_length)\n",
        "            y = np_utils.to_categorical(label_word, vocab_size)\n",
        "            yield (x, y)\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TheMQ-EFv0h-",
        "outputId": "7be343dd-8693-46b5-a89b-0ee29d3e9088"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Test this out for some samples\n",
        "i = 0\n",
        "for x, y in generate_context_word_pairs(corpus=wids, window_size=window_size, vocab_size=vocab_size):\n",
        "    if 0 not in x[0]:\n",
        "        print('Context (X):', [id2word[w] for w in x[0]], '-> Target (Y):', id2word[np.argwhere(y[0])[0][0]])\n",
        "    \n",
        "        if i == 10:\n",
        "            break\n",
        "        i += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Context (X): ['the', 'speed', 'transmission', 'is'] -> Target (Y): of\n",
            "Context (X): ['speed', 'of', 'is', 'an'] -> Target (Y): transmission\n",
            "Context (X): ['of', 'transmission', 'an', 'important'] -> Target (Y): is\n",
            "Context (X): ['transmission', 'is', 'important', 'point'] -> Target (Y): an\n",
            "Context (X): ['is', 'an', 'point', 'of'] -> Target (Y): important\n",
            "Context (X): ['an', 'important', 'of', 'difference'] -> Target (Y): point\n",
            "Context (X): ['important', 'point', 'difference', 'between'] -> Target (Y): of\n",
            "Context (X): ['point', 'of', 'between', 'the'] -> Target (Y): difference\n",
            "Context (X): ['of', 'difference', 'the', 'two'] -> Target (Y): between\n",
            "Context (X): ['difference', 'between', 'two', 'viruses'] -> Target (Y): the\n",
            "Context (X): ['between', 'the', 'viruses', 'influenza'] -> Target (Y): two\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NmWoU81PWBu",
        "outputId": "0d5df2eb-bab8-4a0d-d662-2b18a6fbec6f"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[13,  1, 23,  3]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQV93egCRq8e"
      },
      "source": [
        "#Build the CBOW model architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRV8kkIeRm4D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFVN9gaXPrAD"
      },
      "source": [
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Lambda\n",
        "\n",
        "# build CBOW architecture\n",
        "cbow = Sequential()\n",
        "cbow.add(Embedding(input_dim=vocab_size, output_dim=embed_size, input_length=window_size*2))\n",
        "cbow.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(embed_size,)))\n",
        "cbow.add(Dense(vocab_size, activation='softmax'))\n",
        "cbow.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_a1FVjXQ-eH",
        "outputId": "b76a4dce-9b5e-40c5-b5a6-e150c1ef1e84"
      },
      "source": [
        "# view model summary\n",
        "print(cbow.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 4, 100)            10300     \n",
            "_________________________________________________________________\n",
            "lambda (Lambda)              (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 103)               10403     \n",
            "=================================================================\n",
            "Total params: 20,703\n",
            "Trainable params: 20,703\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "laWEEkZbRBFF",
        "outputId": "7d88bcc3-1c86-48aa-ade7-63eb1a0ad6ca"
      },
      "source": [
        "# visualize model structure\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(cbow, show_shapes=True, show_layer_names=False, \n",
        "                 rankdir='TB').create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"405pt\" viewBox=\"0.00 0.00 227.00 304.00\" width=\"303pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 300)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-300 223,-300 223,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139760804137616 -->\n<g class=\"node\" id=\"node1\">\n<title>139760804137616</title>\n<polygon fill=\"none\" points=\"12.5,-249.5 12.5,-295.5 206.5,-295.5 206.5,-249.5 12.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"52.5\" y=\"-268.8\">InputLayer</text>\n<polyline fill=\"none\" points=\"92.5,-249.5 92.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"121.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"92.5,-272.5 150.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"121.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"150.5,-249.5 150.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178.5\" y=\"-280.3\">[(?, 4)]</text>\n<polyline fill=\"none\" points=\"150.5,-272.5 206.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178.5\" y=\"-257.3\">[(?, 4)]</text>\n</g>\n<!-- 139760804136776 -->\n<g class=\"node\" id=\"node2\">\n<title>139760804136776</title>\n<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 219,-212.5 219,-166.5 0,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"42\" y=\"-185.8\">Embedding</text>\n<polyline fill=\"none\" points=\"84,-166.5 84,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"84,-189.5 142,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"142,-166.5 142,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"180.5\" y=\"-197.3\">(?, 4)</text>\n<polyline fill=\"none\" points=\"142,-189.5 219,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"180.5\" y=\"-174.3\">(?, 4, 100)</text>\n</g>\n<!-- 139760804137616&#45;&gt;139760804136776 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139760804137616-&gt;139760804136776</title>\n<path d=\"M109.5,-249.3799C109.5,-241.1745 109.5,-231.7679 109.5,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"113.0001,-222.784 109.5,-212.784 106.0001,-222.784 113.0001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139760804138960 -->\n<g class=\"node\" id=\"node3\">\n<title>139760804138960</title>\n<polygon fill=\"none\" points=\"10,-83.5 10,-129.5 209,-129.5 209,-83.5 10,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"42\" y=\"-102.8\">Lambda</text>\n<polyline fill=\"none\" points=\"74,-83.5 74,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"74,-106.5 132,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"132,-83.5 132,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170.5\" y=\"-114.3\">(?, 4, 100)</text>\n<polyline fill=\"none\" points=\"132,-106.5 209,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170.5\" y=\"-91.3\">(?, 100)</text>\n</g>\n<!-- 139760804136776&#45;&gt;139760804138960 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139760804136776-&gt;139760804138960</title>\n<path d=\"M109.5,-166.3799C109.5,-158.1745 109.5,-148.7679 109.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"113.0001,-139.784 109.5,-129.784 106.0001,-139.784 113.0001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139760811463008 -->\n<g class=\"node\" id=\"node4\">\n<title>139760811463008</title>\n<polygon fill=\"none\" points=\"23.5,-.5 23.5,-46.5 195.5,-46.5 195.5,-.5 23.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"49.5\" y=\"-19.8\">Dense</text>\n<polyline fill=\"none\" points=\"75.5,-.5 75.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"75.5,-23.5 133.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"133.5,-.5 133.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"164.5\" y=\"-31.3\">(?, 100)</text>\n<polyline fill=\"none\" points=\"133.5,-23.5 195.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"164.5\" y=\"-8.3\">(?, 103)</text>\n</g>\n<!-- 139760804138960&#45;&gt;139760811463008 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139760804138960-&gt;139760811463008</title>\n<path d=\"M109.5,-83.3799C109.5,-75.1745 109.5,-65.7679 109.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"113.0001,-56.784 109.5,-46.784 106.0001,-56.784 113.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnFa9v4bRzNu"
      },
      "source": [
        "#Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idU1ei4fRyGe",
        "outputId": "30f29c8b-c1a4-47e6-9098-8e9941c4293a"
      },
      "source": [
        "for epoch in range(1, 10):\n",
        "    loss = 0.\n",
        "    i = 0\n",
        "    for x, y in generate_context_word_pairs(corpus=wids, window_size=window_size, vocab_size=vocab_size):\n",
        "        i += 1\n",
        "        loss += cbow.train_on_batch(x, y)\n",
        "        if i % 100000 == 0:\n",
        "\n",
        "          print('Processed {} (context, word) pairs'.format(i))\n",
        "\n",
        "    print('Epoch:', epoch, '\\tLoss:', loss)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tLoss: 916.7771601676941\n",
            "\n",
            "Epoch: 2 \tLoss: 901.1807432174683\n",
            "\n",
            "Epoch: 3 \tLoss: 882.9983923435211\n",
            "\n",
            "Epoch: 4 \tLoss: 861.1319408416748\n",
            "\n",
            "Epoch: 5 \tLoss: 837.3939559459686\n",
            "\n",
            "Epoch: 6 \tLoss: 814.7423787117004\n",
            "\n",
            "Epoch: 7 \tLoss: 794.7205078601837\n",
            "\n",
            "Epoch: 8 \tLoss: 776.9589866399765\n",
            "\n",
            "Epoch: 9 \tLoss: 760.457451581955\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNOK03rDVL5k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1HeNH-G6IZg"
      },
      "source": [
        "# Get Word Embeddings\n",
        "\n",
        "To get word embeddings for our entire vocabulary, we can extract out the same from our embedding layer by leveraging the following code. We don’t take the embedding at position 0 since it belongs to the padding (PAD) term which is not really a word of interest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "nugQ0jMy6GQ_",
        "outputId": "2abe1b45-50b5-4b6f-aa9b-2457612edfff"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "weights = cbow.get_weights()[0]\n",
        "weights = weights[1:]\n",
        "print(weights.shape)\n",
        "\n",
        "pd.DataFrame(weights, index=list(id2word.values())[1:]).head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(102, 100)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>of</th>\n",
              "      <td>0.112062</td>\n",
              "      <td>-0.047218</td>\n",
              "      <td>-0.113946</td>\n",
              "      <td>0.209475</td>\n",
              "      <td>0.269026</td>\n",
              "      <td>-0.077178</td>\n",
              "      <td>-0.038582</td>\n",
              "      <td>-0.111159</td>\n",
              "      <td>0.100456</td>\n",
              "      <td>-0.241625</td>\n",
              "      <td>-0.008675</td>\n",
              "      <td>-0.195672</td>\n",
              "      <td>-0.106372</td>\n",
              "      <td>0.029449</td>\n",
              "      <td>-0.153155</td>\n",
              "      <td>-0.014730</td>\n",
              "      <td>0.126183</td>\n",
              "      <td>-0.211955</td>\n",
              "      <td>0.038290</td>\n",
              "      <td>-0.005403</td>\n",
              "      <td>-0.065005</td>\n",
              "      <td>0.256485</td>\n",
              "      <td>-0.029725</td>\n",
              "      <td>0.125112</td>\n",
              "      <td>0.154758</td>\n",
              "      <td>0.124861</td>\n",
              "      <td>0.156184</td>\n",
              "      <td>-0.101601</td>\n",
              "      <td>-0.014551</td>\n",
              "      <td>0.045208</td>\n",
              "      <td>-0.111648</td>\n",
              "      <td>0.091469</td>\n",
              "      <td>0.022983</td>\n",
              "      <td>0.018230</td>\n",
              "      <td>-0.145927</td>\n",
              "      <td>-0.037400</td>\n",
              "      <td>0.006920</td>\n",
              "      <td>0.068704</td>\n",
              "      <td>0.020458</td>\n",
              "      <td>-0.014327</td>\n",
              "      <td>...</td>\n",
              "      <td>0.183808</td>\n",
              "      <td>0.012241</td>\n",
              "      <td>-0.143014</td>\n",
              "      <td>-0.170598</td>\n",
              "      <td>0.064328</td>\n",
              "      <td>0.048416</td>\n",
              "      <td>-0.325232</td>\n",
              "      <td>0.069201</td>\n",
              "      <td>-0.187607</td>\n",
              "      <td>0.027784</td>\n",
              "      <td>0.024834</td>\n",
              "      <td>0.222582</td>\n",
              "      <td>-0.117190</td>\n",
              "      <td>0.072456</td>\n",
              "      <td>-0.173758</td>\n",
              "      <td>-0.010142</td>\n",
              "      <td>0.057604</td>\n",
              "      <td>-0.068918</td>\n",
              "      <td>0.065478</td>\n",
              "      <td>0.091933</td>\n",
              "      <td>0.072361</td>\n",
              "      <td>-0.176073</td>\n",
              "      <td>-0.322837</td>\n",
              "      <td>0.064980</td>\n",
              "      <td>0.022783</td>\n",
              "      <td>-0.045285</td>\n",
              "      <td>0.240385</td>\n",
              "      <td>0.125138</td>\n",
              "      <td>0.038820</td>\n",
              "      <td>0.172238</td>\n",
              "      <td>0.011889</td>\n",
              "      <td>0.159918</td>\n",
              "      <td>-0.162952</td>\n",
              "      <td>0.133516</td>\n",
              "      <td>-0.070316</td>\n",
              "      <td>-0.102483</td>\n",
              "      <td>-0.107778</td>\n",
              "      <td>0.038140</td>\n",
              "      <td>0.094940</td>\n",
              "      <td>0.133823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>influenza</th>\n",
              "      <td>0.119051</td>\n",
              "      <td>-0.034225</td>\n",
              "      <td>-0.114564</td>\n",
              "      <td>-0.218726</td>\n",
              "      <td>0.220310</td>\n",
              "      <td>-0.096452</td>\n",
              "      <td>-0.026509</td>\n",
              "      <td>0.104066</td>\n",
              "      <td>0.137327</td>\n",
              "      <td>-0.156783</td>\n",
              "      <td>-0.009947</td>\n",
              "      <td>-0.002178</td>\n",
              "      <td>0.141789</td>\n",
              "      <td>-0.102039</td>\n",
              "      <td>-0.080870</td>\n",
              "      <td>-0.241272</td>\n",
              "      <td>0.045098</td>\n",
              "      <td>0.004000</td>\n",
              "      <td>-0.005138</td>\n",
              "      <td>-0.269697</td>\n",
              "      <td>-0.053071</td>\n",
              "      <td>-0.210913</td>\n",
              "      <td>-0.041700</td>\n",
              "      <td>0.011692</td>\n",
              "      <td>0.121624</td>\n",
              "      <td>0.084441</td>\n",
              "      <td>0.072778</td>\n",
              "      <td>-0.319435</td>\n",
              "      <td>0.059725</td>\n",
              "      <td>0.013999</td>\n",
              "      <td>0.059608</td>\n",
              "      <td>-0.009320</td>\n",
              "      <td>0.131085</td>\n",
              "      <td>-0.213301</td>\n",
              "      <td>-0.036188</td>\n",
              "      <td>-0.038280</td>\n",
              "      <td>0.025918</td>\n",
              "      <td>0.119472</td>\n",
              "      <td>-0.030240</td>\n",
              "      <td>-0.155014</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.085534</td>\n",
              "      <td>-0.157936</td>\n",
              "      <td>-0.064010</td>\n",
              "      <td>0.231003</td>\n",
              "      <td>0.001815</td>\n",
              "      <td>-0.129234</td>\n",
              "      <td>-0.062647</td>\n",
              "      <td>-0.075812</td>\n",
              "      <td>0.206643</td>\n",
              "      <td>0.017884</td>\n",
              "      <td>0.070241</td>\n",
              "      <td>0.148228</td>\n",
              "      <td>0.049549</td>\n",
              "      <td>0.092701</td>\n",
              "      <td>-0.056164</td>\n",
              "      <td>-0.049719</td>\n",
              "      <td>0.050651</td>\n",
              "      <td>-0.077099</td>\n",
              "      <td>0.089274</td>\n",
              "      <td>-0.014415</td>\n",
              "      <td>-0.123252</td>\n",
              "      <td>-0.024002</td>\n",
              "      <td>0.069416</td>\n",
              "      <td>0.012116</td>\n",
              "      <td>0.136527</td>\n",
              "      <td>0.045648</td>\n",
              "      <td>-0.113655</td>\n",
              "      <td>-0.032994</td>\n",
              "      <td>0.021036</td>\n",
              "      <td>0.027721</td>\n",
              "      <td>0.024262</td>\n",
              "      <td>-0.145594</td>\n",
              "      <td>0.083222</td>\n",
              "      <td>0.074049</td>\n",
              "      <td>0.053823</td>\n",
              "      <td>0.015658</td>\n",
              "      <td>-0.083082</td>\n",
              "      <td>0.314615</td>\n",
              "      <td>-0.073180</td>\n",
              "      <td>0.034965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>covid</th>\n",
              "      <td>-0.061828</td>\n",
              "      <td>0.112045</td>\n",
              "      <td>-0.022188</td>\n",
              "      <td>-0.055370</td>\n",
              "      <td>0.116595</td>\n",
              "      <td>0.001476</td>\n",
              "      <td>-0.073494</td>\n",
              "      <td>0.070374</td>\n",
              "      <td>-0.194650</td>\n",
              "      <td>0.072400</td>\n",
              "      <td>0.019873</td>\n",
              "      <td>-0.041489</td>\n",
              "      <td>0.011938</td>\n",
              "      <td>-0.101422</td>\n",
              "      <td>-0.073957</td>\n",
              "      <td>-0.104975</td>\n",
              "      <td>0.002469</td>\n",
              "      <td>-0.052784</td>\n",
              "      <td>-0.150773</td>\n",
              "      <td>0.028617</td>\n",
              "      <td>0.064659</td>\n",
              "      <td>0.018168</td>\n",
              "      <td>-0.108262</td>\n",
              "      <td>-0.070047</td>\n",
              "      <td>0.054628</td>\n",
              "      <td>0.049606</td>\n",
              "      <td>0.019609</td>\n",
              "      <td>0.215314</td>\n",
              "      <td>0.116572</td>\n",
              "      <td>0.118349</td>\n",
              "      <td>0.051473</td>\n",
              "      <td>0.083614</td>\n",
              "      <td>0.074166</td>\n",
              "      <td>0.028119</td>\n",
              "      <td>-0.073903</td>\n",
              "      <td>-0.104330</td>\n",
              "      <td>0.157401</td>\n",
              "      <td>0.057625</td>\n",
              "      <td>-0.077917</td>\n",
              "      <td>-0.000878</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.036996</td>\n",
              "      <td>-0.142865</td>\n",
              "      <td>-0.054206</td>\n",
              "      <td>0.096568</td>\n",
              "      <td>-0.122085</td>\n",
              "      <td>0.075317</td>\n",
              "      <td>0.022153</td>\n",
              "      <td>-0.024870</td>\n",
              "      <td>0.011049</td>\n",
              "      <td>0.103524</td>\n",
              "      <td>-0.081706</td>\n",
              "      <td>-0.040577</td>\n",
              "      <td>0.194434</td>\n",
              "      <td>0.000625</td>\n",
              "      <td>0.060181</td>\n",
              "      <td>-0.108825</td>\n",
              "      <td>-0.072592</td>\n",
              "      <td>-0.107556</td>\n",
              "      <td>0.131894</td>\n",
              "      <td>-0.089392</td>\n",
              "      <td>0.017899</td>\n",
              "      <td>-0.073382</td>\n",
              "      <td>-0.117550</td>\n",
              "      <td>-0.120043</td>\n",
              "      <td>-0.021395</td>\n",
              "      <td>-0.154074</td>\n",
              "      <td>-0.154050</td>\n",
              "      <td>0.002622</td>\n",
              "      <td>-0.014315</td>\n",
              "      <td>0.151098</td>\n",
              "      <td>0.058650</td>\n",
              "      <td>0.056378</td>\n",
              "      <td>0.033518</td>\n",
              "      <td>-0.033823</td>\n",
              "      <td>0.045372</td>\n",
              "      <td>-0.174040</td>\n",
              "      <td>-0.069892</td>\n",
              "      <td>0.017427</td>\n",
              "      <td>-0.090405</td>\n",
              "      <td>0.027957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.192891</td>\n",
              "      <td>0.151063</td>\n",
              "      <td>-0.245152</td>\n",
              "      <td>0.080008</td>\n",
              "      <td>0.232050</td>\n",
              "      <td>-0.069970</td>\n",
              "      <td>-0.197555</td>\n",
              "      <td>-0.282972</td>\n",
              "      <td>-0.007938</td>\n",
              "      <td>0.089446</td>\n",
              "      <td>0.227578</td>\n",
              "      <td>-0.077005</td>\n",
              "      <td>0.081593</td>\n",
              "      <td>-0.349372</td>\n",
              "      <td>-0.127501</td>\n",
              "      <td>-0.068333</td>\n",
              "      <td>-0.133049</td>\n",
              "      <td>-0.018811</td>\n",
              "      <td>0.099768</td>\n",
              "      <td>-0.216592</td>\n",
              "      <td>-0.042711</td>\n",
              "      <td>0.211243</td>\n",
              "      <td>0.077070</td>\n",
              "      <td>-0.271613</td>\n",
              "      <td>0.115267</td>\n",
              "      <td>-0.109612</td>\n",
              "      <td>-0.001717</td>\n",
              "      <td>0.247629</td>\n",
              "      <td>0.190257</td>\n",
              "      <td>0.275107</td>\n",
              "      <td>-0.216127</td>\n",
              "      <td>-0.070994</td>\n",
              "      <td>-0.093697</td>\n",
              "      <td>0.214013</td>\n",
              "      <td>-0.116979</td>\n",
              "      <td>-0.012601</td>\n",
              "      <td>-0.112563</td>\n",
              "      <td>0.076699</td>\n",
              "      <td>0.025365</td>\n",
              "      <td>-0.245795</td>\n",
              "      <td>...</td>\n",
              "      <td>0.084272</td>\n",
              "      <td>-0.154540</td>\n",
              "      <td>0.235247</td>\n",
              "      <td>0.204614</td>\n",
              "      <td>-0.276276</td>\n",
              "      <td>0.212488</td>\n",
              "      <td>-0.145338</td>\n",
              "      <td>0.254858</td>\n",
              "      <td>-0.168586</td>\n",
              "      <td>-0.126773</td>\n",
              "      <td>0.189597</td>\n",
              "      <td>-0.099073</td>\n",
              "      <td>0.117837</td>\n",
              "      <td>-0.214199</td>\n",
              "      <td>-0.068141</td>\n",
              "      <td>-0.057593</td>\n",
              "      <td>-0.052636</td>\n",
              "      <td>-0.281147</td>\n",
              "      <td>-0.001224</td>\n",
              "      <td>0.118177</td>\n",
              "      <td>-0.220656</td>\n",
              "      <td>-0.221897</td>\n",
              "      <td>0.092753</td>\n",
              "      <td>-0.022399</td>\n",
              "      <td>-0.216110</td>\n",
              "      <td>-0.331790</td>\n",
              "      <td>-0.182279</td>\n",
              "      <td>-0.146344</td>\n",
              "      <td>0.116650</td>\n",
              "      <td>0.000485</td>\n",
              "      <td>0.161600</td>\n",
              "      <td>0.074467</td>\n",
              "      <td>0.067485</td>\n",
              "      <td>0.291568</td>\n",
              "      <td>-0.095380</td>\n",
              "      <td>-0.184805</td>\n",
              "      <td>-0.067623</td>\n",
              "      <td>-0.114364</td>\n",
              "      <td>-0.255627</td>\n",
              "      <td>-0.159847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>virus</th>\n",
              "      <td>-0.015558</td>\n",
              "      <td>0.216286</td>\n",
              "      <td>-0.107263</td>\n",
              "      <td>-0.007987</td>\n",
              "      <td>0.037643</td>\n",
              "      <td>0.040900</td>\n",
              "      <td>-0.197752</td>\n",
              "      <td>-0.307170</td>\n",
              "      <td>0.076825</td>\n",
              "      <td>0.126949</td>\n",
              "      <td>0.166177</td>\n",
              "      <td>-0.251641</td>\n",
              "      <td>0.253372</td>\n",
              "      <td>-0.311635</td>\n",
              "      <td>-0.348639</td>\n",
              "      <td>-0.134607</td>\n",
              "      <td>0.151609</td>\n",
              "      <td>0.230544</td>\n",
              "      <td>-0.041744</td>\n",
              "      <td>-0.165532</td>\n",
              "      <td>0.056047</td>\n",
              "      <td>-0.019456</td>\n",
              "      <td>0.021712</td>\n",
              "      <td>0.143823</td>\n",
              "      <td>0.200389</td>\n",
              "      <td>-0.188323</td>\n",
              "      <td>0.167920</td>\n",
              "      <td>0.131973</td>\n",
              "      <td>-0.049267</td>\n",
              "      <td>0.112399</td>\n",
              "      <td>-0.284573</td>\n",
              "      <td>-0.019214</td>\n",
              "      <td>-0.107574</td>\n",
              "      <td>0.180062</td>\n",
              "      <td>-0.088433</td>\n",
              "      <td>0.056366</td>\n",
              "      <td>-0.118209</td>\n",
              "      <td>0.200650</td>\n",
              "      <td>0.205804</td>\n",
              "      <td>-0.144054</td>\n",
              "      <td>...</td>\n",
              "      <td>0.099328</td>\n",
              "      <td>-0.038302</td>\n",
              "      <td>0.158704</td>\n",
              "      <td>0.105680</td>\n",
              "      <td>-0.268480</td>\n",
              "      <td>-0.141596</td>\n",
              "      <td>-0.038366</td>\n",
              "      <td>0.195109</td>\n",
              "      <td>-0.076811</td>\n",
              "      <td>-0.057677</td>\n",
              "      <td>-0.237602</td>\n",
              "      <td>-0.080625</td>\n",
              "      <td>0.275230</td>\n",
              "      <td>-0.313964</td>\n",
              "      <td>0.228361</td>\n",
              "      <td>0.007577</td>\n",
              "      <td>0.216850</td>\n",
              "      <td>-0.223790</td>\n",
              "      <td>0.246008</td>\n",
              "      <td>0.131190</td>\n",
              "      <td>-0.098962</td>\n",
              "      <td>-0.189890</td>\n",
              "      <td>0.122458</td>\n",
              "      <td>-0.222174</td>\n",
              "      <td>0.010485</td>\n",
              "      <td>-0.309248</td>\n",
              "      <td>-0.277118</td>\n",
              "      <td>-0.164897</td>\n",
              "      <td>0.033664</td>\n",
              "      <td>0.130767</td>\n",
              "      <td>-0.232458</td>\n",
              "      <td>-0.267618</td>\n",
              "      <td>0.170729</td>\n",
              "      <td>0.219578</td>\n",
              "      <td>-0.173495</td>\n",
              "      <td>-0.225727</td>\n",
              "      <td>0.080486</td>\n",
              "      <td>-0.182135</td>\n",
              "      <td>-0.116772</td>\n",
              "      <td>0.030997</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0         1         2   ...        97        98        99\n",
              "of         0.112062 -0.047218 -0.113946  ...  0.038140  0.094940  0.133823\n",
              "influenza  0.119051 -0.034225 -0.114564  ...  0.314615 -0.073180  0.034965\n",
              "covid     -0.061828  0.112045 -0.022188  ...  0.017427 -0.090405  0.027957\n",
              "19         0.192891  0.151063 -0.245152  ... -0.114364 -0.255627 -0.159847\n",
              "virus     -0.015558  0.216286 -0.107263  ... -0.182135 -0.116772  0.030997\n",
              "\n",
              "[5 rows x 100 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCl9E-Vl77Uv",
        "outputId": "7a5695cf-a7c2-4507-b185-cd3d980375bf"
      },
      "source": [
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "# compute pairwise distance matrix\n",
        "distance_matrix = euclidean_distances(weights)\n",
        "print(distance_matrix.shape)\n",
        "\n",
        "# view contextually similar words\n",
        "similar_words = {search_term: [id2word[idx] for idx in distance_matrix[word2id[search_term]-1].argsort()[1:5]+1] \n",
        "                   for search_term in ['illness','transmission', 'is', 'important', 'point']}\n",
        "\n",
        "similar_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(102, 102)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'illness': ['pre', 'means', 'or', 'infections'],\n",
              " 'important': ['an', 'point', 'infections', 'estimated'],\n",
              " 'is': ['understood', 'appearance', 'appear', 'estimated'],\n",
              " 'point': ['important', 'infections', 'secondary', 'an'],\n",
              " 'transmission': ['–transmission', 'major', 'speed', 'in']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmY9IO2DkRnb"
      },
      "source": [
        "# CBOW_word2vec_keras_example: 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzVsp1kUVQkS"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(13)\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Lambda\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "import gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCIhI_kvWWWZ",
        "outputId": "6b60f816-b169-4182-f77a-d4e0a0b675fd"
      },
      "source": [
        "path = get_file('alice.txt', origin='http://www.gutenberg.org/files/11/11-0.txt')\n",
        "corpus = open(path).readlines()[:300]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://www.gutenberg.org/files/11/11-0.txt\n",
            "180224/174693 [==============================] - 0s 2us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CVnA0Vl8ysG"
      },
      "source": [
        "corpus = [sentence for sentence in corpus if sentence.count(' ') >= 2]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQcN4ZLBnsyi"
      },
      "source": [
        "# Tokenization then Transforms each text in texts to a sequence of integers\n",
        "\n",
        "texts_to_sequences. Transforms each text in texts to a sequence of integers. Only top num_words-1 most frequent words will be taken into account. Only words known by the tokenizer will be taken into account."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "159H8A0T8Fgi"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "corpus = tokenizer.texts_to_sequences(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8MYFohi9K9E"
      },
      "source": [
        "nb_samples = sum(len(s) for s in corpus) # no. of word samples in corpus\n",
        "V = len(tokenizer.word_index) + 1  # tokenizer.word_index:dictionary of words and their uniquely assigned integers. V: vocab size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ6PUpxbx70O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQskxVuG-JjN"
      },
      "source": [
        "dim = 100   # embedding size\n",
        "window_size = 2  # context window size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeHxzQGoLTuA"
      },
      "source": [
        "def generate_data(corpus, window_size, V):\n",
        "    maxlen = window_size*2\n",
        "    for words in corpus:\n",
        "        L = len(words)\n",
        "        for index, word in enumerate(words):\n",
        "            contexts = []\n",
        "            labels   = []            \n",
        "            s = index - window_size\n",
        "            e = index + window_size + 1\n",
        "            \n",
        "            contexts.append([words[i] for i in range(s, e) if 0 <= i < L and i != index])\n",
        "            labels.append(word)\n",
        "\n",
        "            x = sequence.pad_sequences(contexts, maxlen=maxlen)\n",
        "            y = np_utils.to_categorical(labels, V)\n",
        "            yield (x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptlCLPc31Uj3"
      },
      "source": [
        "# Creating a reverse dictionary(sequence_to_text in keras)\n",
        "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "517enXSy-K6n",
        "outputId": "92db8145-96f2-42ae-adf5-42eeafee08c6"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Test this out for some samples\n",
        "i = 0\n",
        "for x, y in generate_context_word_pairs(corpus=corpus, window_size=window_size, vocab_size=V):\n",
        "    if 0 not in x[0]:\n",
        "        print('Context (X):', [reverse_word_map[w] for w in x[0]], '-> Target (Y):', reverse_word_map[np.argwhere(y[0])[0][0]])\n",
        "    \n",
        "        if i == 10:\n",
        "            break\n",
        "        i += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Context (X): ['\\ufeffthe', 'project', 'ebook', 'of'] -> Target (Y): gutenberg\n",
            "Context (X): ['project', 'gutenberg', 'of', 'alice’s'] -> Target (Y): ebook\n",
            "Context (X): ['gutenberg', 'ebook', 'alice’s', 'adventures'] -> Target (Y): of\n",
            "Context (X): ['ebook', 'of', 'adventures', 'in'] -> Target (Y): alice’s\n",
            "Context (X): ['of', 'alice’s', 'in', 'wonderland'] -> Target (Y): adventures\n",
            "Context (X): ['alice’s', 'adventures', 'wonderland', 'by'] -> Target (Y): in\n",
            "Context (X): ['adventures', 'in', 'by', 'lewis'] -> Target (Y): wonderland\n",
            "Context (X): ['in', 'wonderland', 'lewis', 'carroll'] -> Target (Y): by\n",
            "Context (X): ['this', 'ebook', 'for', 'the'] -> Target (Y): is\n",
            "Context (X): ['ebook', 'is', 'the', 'use'] -> Target (Y): for\n",
            "Context (X): ['is', 'for', 'use', 'of'] -> Target (Y): the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OHFDc0YLYPv",
        "outputId": "c04758dd-152b-4a53-c521-a6374cab7c14"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[61, 17, 62,  8]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w96rcJcEPBqm"
      },
      "source": [
        "build CBOW Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92kSXln6XVCZ"
      },
      "source": [
        "cbow = Sequential()\n",
        "cbow.add(Embedding(input_dim=V, output_dim=dim, input_length=window_size*2))\n",
        "cbow.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(dim,)))\n",
        "cbow.add(Dense(V, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_uH8hVrXXz_"
      },
      "source": [
        "cbow.compile(loss='categorical_crossentropy', optimizer='adadelta')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WC9gZfdD7aO",
        "outputId": "371e92af-f2b5-4c15-d2da-9a6f8550aea9"
      },
      "source": [
        "for ite in range(10):\n",
        "    loss = 0.\n",
        "    for x, y in generate_data(corpus, window_size, V):\n",
        "        loss += cbow.train_on_batch(x, y)\n",
        "\n",
        "    #print(ite, loss)\n",
        "    print('Epoch:', ite, '\\tLoss:', loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 \tLoss: 17477.16960287094\n",
            "Epoch: 1 \tLoss: 17474.020650863647\n",
            "Epoch: 2 \tLoss: 17470.8741645813\n",
            "Epoch: 3 \tLoss: 17467.73010778427\n",
            "Epoch: 4 \tLoss: 17464.588492393494\n",
            "Epoch: 5 \tLoss: 17461.449332237244\n",
            "Epoch: 6 \tLoss: 17458.312631607056\n",
            "Epoch: 7 \tLoss: 17455.17835521698\n",
            "Epoch: 8 \tLoss: 17452.046567440033\n",
            "Epoch: 9 \tLoss: 17448.917232513428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxrZeewND7rV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STh8FYs-O-xM",
        "outputId": "76ebc342-406c-4110-b7bf-a708c4c4c0f0"
      },
      "source": [
        "f = open('vectors.txt' ,'w')\n",
        "f.write('{} {}\\n'.format(V-1, dim))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULn-bGoaVDF3"
      },
      "source": [
        "vectors = cbow.get_weights()[0]\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    str_vec = ' '.join(map(str, list(vectors[i, :])))\n",
        "    f.write('{} {}\\n'.format(word, str_vec))\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj2gjRLkQUZy"
      },
      "source": [
        "w2v = gensim.models.KeyedVectors.load_word2vec_format('./vectors.txt', binary=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rp4dvqXHQZRU",
        "outputId": "cf08d24f-5bee-410e-b86d-f569acb234ff"
      },
      "source": [
        "w2v.most_similar(positive=['the'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('shutting', 0.3209899961948395),\n",
              " ('give', 0.26713377237319946),\n",
              " ('actually', 0.2627982199192047),\n",
              " ('house', 0.2582211494445801),\n",
              " ('jumped', 0.2550831735134125),\n",
              " ('\\ufeffthe', 0.24545744061470032),\n",
              " ('ears', 0.2348078191280365),\n",
              " ('without', 0.23361985385417938),\n",
              " ('flame', 0.22705873847007751),\n",
              " ('bye', 0.22394752502441406)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1wHWeqA84GW",
        "outputId": "74fc4e5b-d5aa-4428-c63d-bf526194931f"
      },
      "source": [
        "\n",
        "w2v.most_similar(positive=['alice'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('written', 0.2921648621559143),\n",
              " ('11', 0.2904602289199829),\n",
              " ('along', 0.27751296758651733),\n",
              " ('world', 0.266973078250885),\n",
              " ('lying', 0.2651062309741974),\n",
              " ('itself', 0.25291574001312256),\n",
              " ('nonsense', 0.251752644777298),\n",
              " ('passage', 0.24955332279205322),\n",
              " ('lobster', 0.24495452642440796),\n",
              " ('where', 0.24381212890148163)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYDhyOj49Bwa",
        "outputId": "ae568bdc-0194-496b-801e-5a0b4b7a22a7"
      },
      "source": [
        "w2v.most_similar(positive=['written'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ground', 0.3064327836036682),\n",
              " ('underneath', 0.29750150442123413),\n",
              " ('alice', 0.2921648621559143),\n",
              " ('knew', 0.2712549567222595),\n",
              " ('where', 0.2450907826423645),\n",
              " ('remained', 0.2410314679145813),\n",
              " ('online', 0.23091895878314972),\n",
              " ('beds', 0.22779256105422974),\n",
              " ('made', 0.21763600409030914),\n",
              " ('author', 0.2154083102941513)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoaDXo2dYY3S"
      },
      "source": [
        "# CBOW_word2vec_pytorch_example: 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUnll5wm9N6l"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch1Wl5vjYoCq"
      },
      "source": [
        "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfk-x9_odLkS"
      },
      "source": [
        "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
        "Computational processes are abstract beings that inhabit computers.\n",
        "As they evolve, processes manipulate other abstract things called data.\n",
        "The evolution of a process is directed by a pattern of rules\n",
        "called a program. People create programs to direct processes. In effect,\n",
        "we conjure the spirits of the computer with our spells.\"\"\".split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhIEJSmTdPTk"
      },
      "source": [
        "# By deriving a set from `raw_text`, we deduplicate the array\n",
        "vocab = set(raw_text)\n",
        "vocab_size = len(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M53fQ3k0xE0d"
      },
      "source": [
        "word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
        "idx_to_word = {i: word for i, word in enumerate(vocab)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV0HLq2ldcej",
        "outputId": "f4062ab3-a423-4878-c567-e6d09dfda233"
      },
      "source": [
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "word_to_ix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'As': 46,\n",
              " 'Computational': 10,\n",
              " 'In': 35,\n",
              " 'People': 34,\n",
              " 'The': 9,\n",
              " 'We': 8,\n",
              " 'a': 5,\n",
              " 'about': 24,\n",
              " 'abstract': 42,\n",
              " 'are': 21,\n",
              " 'beings': 6,\n",
              " 'by': 41,\n",
              " 'called': 19,\n",
              " 'computational': 37,\n",
              " 'computer': 4,\n",
              " 'computers.': 28,\n",
              " 'conjure': 25,\n",
              " 'create': 29,\n",
              " 'data.': 7,\n",
              " 'direct': 43,\n",
              " 'directed': 3,\n",
              " 'effect,': 1,\n",
              " 'evolution': 13,\n",
              " 'evolve,': 17,\n",
              " 'idea': 32,\n",
              " 'inhabit': 33,\n",
              " 'is': 47,\n",
              " 'manipulate': 18,\n",
              " 'of': 36,\n",
              " 'other': 16,\n",
              " 'our': 26,\n",
              " 'pattern': 15,\n",
              " 'process': 14,\n",
              " 'process.': 45,\n",
              " 'processes': 23,\n",
              " 'processes.': 27,\n",
              " 'program.': 44,\n",
              " 'programs': 11,\n",
              " 'rules': 22,\n",
              " 'spells.': 20,\n",
              " 'spirits': 31,\n",
              " 'study': 39,\n",
              " 'that': 40,\n",
              " 'the': 30,\n",
              " 'they': 48,\n",
              " 'things': 38,\n",
              " 'to': 0,\n",
              " 'we': 2,\n",
              " 'with': 12}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLlydA3OdeEa",
        "outputId": "746a1d71-cc90-44ba-e286-49f1392d9b46"
      },
      "source": [
        "data = []\n",
        "for i in range(2, len(raw_text) - 2):\n",
        "    context = [raw_text[i - 2], raw_text[i - 1],\n",
        "               raw_text[i + 1], raw_text[i + 2]]\n",
        "    target = raw_text[i]\n",
        "    data.append((context, target))\n",
        "print(data[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(['We', 'are', 'to', 'study'], 'about'), (['are', 'about', 'study', 'the'], 'to'), (['about', 'to', 'the', 'idea'], 'study'), (['to', 'study', 'idea', 'of'], 'the'), (['study', 'the', 'of', 'a'], 'idea')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zLLs9UXtU1l"
      },
      "source": [
        "def make_context_vector(context, word_to_ix):\n",
        "    idxs = [word_to_ix[w] for w in context]\n",
        "    return torch.tensor(idxs, dtype=torch.long)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBpR5Yx5pTuy"
      },
      "source": [
        "built CBOW model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOJHBb-QpSj2"
      },
      "source": [
        "class CBOW(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(CBOW, self).__init__()\n",
        "\n",
        "        #out: 1 x emdedding_dim\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(embedding_dim, 128)\n",
        "        self.activation_function1 = nn.ReLU()\n",
        "        \n",
        "        #out: 1 x vocab_size\n",
        "        self.linear2 = nn.Linear(128, vocab_size)\n",
        "        self.activation_function2 = nn.LogSoftmax(dim = -1)\n",
        "        \n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = sum(self.embeddings(inputs)).view(1,-1)\n",
        "        out = self.linear1(embeds)\n",
        "        out = self.activation_function1(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.activation_function2(out)\n",
        "        return out\n",
        "\n",
        "    def get_word_emdedding(self, word):\n",
        "        word = torch.tensor([word_to_ix[word]])\n",
        "        return self.embeddings(word).view(1,-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0aEuzGgd_Fq"
      },
      "source": [
        "EMDEDDING_DIM = 100\n",
        "model = CBOW(vocab_size, EMDEDDING_DIM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIgqv3KprkQO"
      },
      "source": [
        "losses = []\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9YN74P8sBll",
        "outputId": "db46f66c-cab0-449f-dc01-d3e8dd971641"
      },
      "source": [
        "#TRAINING\n",
        "for epoch in range(50):\n",
        "    total_loss = 0\n",
        "\n",
        "    for context, target in data:\n",
        "        context_vector = make_context_vector(context, word_to_ix)  \n",
        "\n",
        "        log_probs = model(context_vector)\n",
        "\n",
        "        total_loss += loss_function(log_probs, torch.tensor([word_to_ix[target]]))\n",
        "\n",
        "    #optimize at the end of each epoch\n",
        "    optimizer.zero_grad()\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "    #total_loss += loss.item()\n",
        "        \n",
        "    losses.append(total_loss)\n",
        "\n",
        "print(losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor(20.4792, grad_fn=<AddBackward0>), tensor(19.6298, grad_fn=<AddBackward0>), tensor(18.8330, grad_fn=<AddBackward0>), tensor(18.0851, grad_fn=<AddBackward0>), tensor(17.3838, grad_fn=<AddBackward0>), tensor(16.7239, grad_fn=<AddBackward0>), tensor(16.1035, grad_fn=<AddBackward0>), tensor(15.5196, grad_fn=<AddBackward0>), tensor(14.9695, grad_fn=<AddBackward0>), tensor(14.4507, grad_fn=<AddBackward0>), tensor(13.9613, grad_fn=<AddBackward0>), tensor(13.4983, grad_fn=<AddBackward0>), tensor(13.0608, grad_fn=<AddBackward0>), tensor(12.6463, grad_fn=<AddBackward0>), tensor(12.2538, grad_fn=<AddBackward0>), tensor(11.8815, grad_fn=<AddBackward0>), tensor(11.5278, grad_fn=<AddBackward0>), tensor(11.1929, grad_fn=<AddBackward0>), tensor(10.8737, grad_fn=<AddBackward0>), tensor(10.5694, grad_fn=<AddBackward0>), tensor(10.2803, grad_fn=<AddBackward0>), tensor(10.0041, grad_fn=<AddBackward0>), tensor(9.7412, grad_fn=<AddBackward0>), tensor(9.4896, grad_fn=<AddBackward0>), tensor(9.2489, grad_fn=<AddBackward0>), tensor(9.0190, grad_fn=<AddBackward0>), tensor(8.7990, grad_fn=<AddBackward0>), tensor(8.5879, grad_fn=<AddBackward0>), tensor(8.3853, grad_fn=<AddBackward0>), tensor(8.1918, grad_fn=<AddBackward0>), tensor(8.0058, grad_fn=<AddBackward0>), tensor(7.8269, grad_fn=<AddBackward0>), tensor(7.6553, grad_fn=<AddBackward0>), tensor(7.4900, grad_fn=<AddBackward0>), tensor(7.3311, grad_fn=<AddBackward0>), tensor(7.1781, grad_fn=<AddBackward0>), tensor(7.0308, grad_fn=<AddBackward0>), tensor(6.8886, grad_fn=<AddBackward0>), tensor(6.7518, grad_fn=<AddBackward0>), tensor(6.6197, grad_fn=<AddBackward0>), tensor(6.4920, grad_fn=<AddBackward0>), tensor(6.3687, grad_fn=<AddBackward0>), tensor(6.2495, grad_fn=<AddBackward0>), tensor(6.1342, grad_fn=<AddBackward0>), tensor(6.0228, grad_fn=<AddBackward0>), tensor(5.9148, grad_fn=<AddBackward0>), tensor(5.8104, grad_fn=<AddBackward0>), tensor(5.7092, grad_fn=<AddBackward0>), tensor(5.6111, grad_fn=<AddBackward0>), tensor(5.5160, grad_fn=<AddBackward0>), tensor(5.4238, grad_fn=<AddBackward0>), tensor(5.3343, grad_fn=<AddBackward0>), tensor(5.2476, grad_fn=<AddBackward0>), tensor(5.1631, grad_fn=<AddBackward0>), tensor(5.0813, grad_fn=<AddBackward0>), tensor(5.0018, grad_fn=<AddBackward0>), tensor(4.9245, grad_fn=<AddBackward0>), tensor(4.8491, grad_fn=<AddBackward0>), tensor(4.7761, grad_fn=<AddBackward0>), tensor(4.7050, grad_fn=<AddBackward0>), tensor(4.6358, grad_fn=<AddBackward0>), tensor(4.5684, grad_fn=<AddBackward0>), tensor(4.5027, grad_fn=<AddBackward0>), tensor(4.4387, grad_fn=<AddBackward0>), tensor(4.3764, grad_fn=<AddBackward0>), tensor(4.3156, grad_fn=<AddBackward0>), tensor(4.2565, grad_fn=<AddBackward0>), tensor(4.1988, grad_fn=<AddBackward0>), tensor(4.1425, grad_fn=<AddBackward0>), tensor(4.0876, grad_fn=<AddBackward0>), tensor(4.0339, grad_fn=<AddBackward0>), tensor(3.9816, grad_fn=<AddBackward0>), tensor(3.9305, grad_fn=<AddBackward0>), tensor(3.8805, grad_fn=<AddBackward0>), tensor(3.8317, grad_fn=<AddBackward0>), tensor(3.7841, grad_fn=<AddBackward0>), tensor(3.7375, grad_fn=<AddBackward0>), tensor(3.6919, grad_fn=<AddBackward0>), tensor(3.6475, grad_fn=<AddBackward0>), tensor(3.6039, grad_fn=<AddBackward0>), tensor(3.5613, grad_fn=<AddBackward0>), tensor(3.5196, grad_fn=<AddBackward0>), tensor(3.4790, grad_fn=<AddBackward0>), tensor(3.4390, grad_fn=<AddBackward0>), tensor(3.4000, grad_fn=<AddBackward0>), tensor(3.3617, grad_fn=<AddBackward0>), tensor(3.3243, grad_fn=<AddBackward0>), tensor(3.2876, grad_fn=<AddBackward0>), tensor(3.2517, grad_fn=<AddBackward0>), tensor(3.2164, grad_fn=<AddBackward0>), tensor(3.1819, grad_fn=<AddBackward0>), tensor(3.1480, grad_fn=<AddBackward0>), tensor(3.1148, grad_fn=<AddBackward0>), tensor(3.0823, grad_fn=<AddBackward0>), tensor(3.0503, grad_fn=<AddBackward0>), tensor(3.0190, grad_fn=<AddBackward0>), tensor(2.9883, grad_fn=<AddBackward0>), tensor(2.9581, grad_fn=<AddBackward0>), tensor(2.9284, grad_fn=<AddBackward0>), tensor(2.8993, grad_fn=<AddBackward0>)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgNEn9ELsfPP"
      },
      "source": [
        "#TESTING\n",
        "context = ['People','create','to', 'direct']\n",
        "context_vector = make_context_vector(context, word_to_ix)\n",
        "a = model(context_vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvmYLP9OwjfA",
        "outputId": "7a6f513b-c9df-4665-b658-73b19a168743"
      },
      "source": [
        "#Print result\n",
        "print(f'Raw text: {\" \".join(raw_text)}\\n')\n",
        "print(f'Context: {context}\\n')\n",
        "print(f'Prediction: {idx_to_word[torch.argmax(a[0]).item()]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Raw text: We are about to study the idea of a computational process. Computational processes are abstract beings that inhabit computers. As they evolve, processes manipulate other abstract things called data. The evolution of a process is directed by a pattern of rules called a program. People create programs to direct processes. In effect, we conjure the spirits of the computer with our spells.\n",
            "\n",
            "Context: ['People', 'create', 'to', 'direct']\n",
            "\n",
            "Prediction: programs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LppaRrN-wmf2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DBjJnCw0XW5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}