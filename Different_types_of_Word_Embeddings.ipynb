{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Different types of Word Embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNtp0fFmFsMcyBnnFnmTbBX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EPRADDH/NLP_Natural_Language_Processing_Methods/blob/main/Different_types_of_Word_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKtPeVRblYKk"
      },
      "source": [
        "Frequency based Embedding\n",
        "\n",
        "# 1. CountVectrization\n",
        "\n",
        "https://colab.research.google.com/drive/1BqYjuYNROdJtb5maA0zlVKM57xwV080w?authuser=2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wfkuUDcNmJ4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqffFuLtv6Fn"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# set of documents\n",
        "train = ['The sky is blue.','The sun is bright.']\n",
        "test = ['The sun in the sky is bright', 'We can see the shining sun, the bright sun.']\n",
        "\n",
        "# instantiate the vectorizer object\n",
        "countvectorizer = CountVectorizer(analyzer= 'word', stop_words='english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io2khyA-xcgt",
        "outputId": "d926709d-320f-4e28-e09e-73ac6b18490a"
      },
      "source": [
        "# convert th documents into a matrix\n",
        "count_wm = countvectorizer.fit_transform(train)\n",
        "count_wm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<2x4 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 4 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4HyvAiAx62a",
        "outputId": "e3a69dfb-9935-4922-e8f7-fcfedafa2ef1"
      },
      "source": [
        "# sparse matrix  count for Doc1 & Doc2\n",
        "count_wm.toarray()   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 1, 0],\n",
              "       [0, 1, 0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ehmJ5XGyktn",
        "outputId": "bf7f8fb6-df7c-4f43-fa14-eb01364979ca"
      },
      "source": [
        "count_tokens = countvectorizer.get_feature_names()\n",
        "count_tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['blue', 'bright', 'sky', 'sun']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP1rjfVAzzl8"
      },
      "source": [
        "df_countvect = pd.DataFrame(data = count_wm.toarray(),index = ['Doc1','Doc2'],columns = count_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "u_nj1hdsz0a_",
        "outputId": "24c8cabb-e322-4492-a0e9-9dec59bcecc6"
      },
      "source": [
        "\n",
        "df_countvect"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>blue</th>\n",
              "      <th>bright</th>\n",
              "      <th>sky</th>\n",
              "      <th>sun</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Doc1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      blue  bright  sky  sun\n",
              "Doc1     1       0    1    0\n",
              "Doc2     0       1    0    1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am2w_VJl0Hyq"
      },
      "source": [
        "#Exampal : 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCE6kyp90G_N"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "train = ('The sky is blue.','The sun is bright.')\n",
        "test = ('The sun in the sky is bright', 'We can see the shining sun, the bright sun.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nz4CoaqLVjX",
        "outputId": "d7690ad3-d818-4b03-8723-c1918fb9b4da"
      },
      "source": [
        "# instantiate the vectorizer object\n",
        "# use analyzer is word and stop_words is english which are responsible for remove stop words and create word vocabulary\n",
        "countvectorizer = CountVectorizer(analyzer='word' , stop_words='english')\n",
        "\n",
        "countvectorizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbu5BNjZLxBW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHIH3SwOLVqg"
      },
      "source": [
        "terms = countvectorizer.fit_transform(train)\n",
        "term_vectors  = countvectorizer.transform(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEIyFg9mLh7c",
        "outputId": "a0961837-1f59-40fe-99bc-ce29a083d813"
      },
      "source": [
        "print(\"Sparse Matrix form of test data : \\n\")\n",
        "print(term_vectors.todense())\n",
        "\n",
        "print(\"Sparse Matrix form of test data : \\n\")\n",
        "print(terms.todense())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sparse Matrix form of test data : \n",
            "\n",
            "[[0 1 1 1]\n",
            " [0 1 0 2]]\n",
            "Sparse Matrix form of test data : \n",
            "\n",
            "[[1 0 1 0]\n",
            " [0 1 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jq-zzEwLvyT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGVLWsyCq8Wx"
      },
      "source": [
        "# 2. TF-IDF vectorization\n",
        "\n",
        "Example 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIAkUko5k3sG"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# set of documents\n",
        "train = ['The sky is blue.','The sun is bright.']\n",
        "test = ['The sun in the sky is bright', 'We can see the shining sun, the bright sun.']\n",
        "\n",
        "# instantiate the vectorizer object\n",
        "tfidfvectorizer = TfidfVectorizer(analyzer='word',stop_words= 'english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12vOL7C2xqt7"
      },
      "source": [
        "# convert th documents into a matrix\n",
        "tfidf_wm = tfidfvectorizer.fit_transform(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG5k5wVS0m4I",
        "outputId": "2e1f9f3b-3a45-4733-9483-2fd251f9f360"
      },
      "source": [
        "# TF-IDF Score for Doc1 & Doc2\n",
        "tfidf_wm.toarray() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.70710678, 0.        , 0.70710678, 0.        ],\n",
              "       [0.        , 0.70710678, 0.        , 0.70710678]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xay1mGVY0ubD",
        "outputId": "d5a59f15-6cf9-4dc9-b063-5330b3ffc537"
      },
      "source": [
        "tfidf_tokens = tfidfvectorizer.get_feature_names()\n",
        "tfidf_tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['blue', 'bright', 'sky', 'sun']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "BeQYLkkK1XIl",
        "outputId": "314381dc-8c6c-434c-90f6-84baedc961e6"
      },
      "source": [
        "df_tfidfvect = pd.DataFrame(data = tfidf_wm.toarray(),index = ['Doc1','Doc2'],columns = tfidf_tokens)\n",
        "\n",
        "df_tfidfvect"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>blue</th>\n",
              "      <th>bright</th>\n",
              "      <th>sky</th>\n",
              "      <th>sun</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Doc1</th>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doc2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707107</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          blue    bright       sky       sun\n",
              "Doc1  0.707107  0.000000  0.707107  0.000000\n",
              "Doc2  0.000000  0.707107  0.000000  0.707107"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkcbq16fHXbE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8qdZ5dyN20p"
      },
      "source": [
        "Example 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JlwQim4M5Go"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "train = ('The sky is blue.','The sun is bright.')\n",
        "test = ('The sun in the sky is bright', 'We can see the shining sun, the bright sun.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i82tAthANDE9"
      },
      "source": [
        "# instantiate the vectorizer object\n",
        "# use analyzer is word and stop_words is english which are responsible for remove stop words and create word vocabulary\n",
        "tfidfvectorizer = TfidfVectorizer(analyzer='word' , stop_words='english',)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rXfNkmMOADY"
      },
      "source": [
        "tfidfvectorizer.fit(train)\n",
        "tfidf_train = tfidfvectorizer.transform(train)\n",
        "tfidf_term_vectors  = tfidfvectorizer.transform(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdcFAp_JOCoe",
        "outputId": "1bcf554c-4336-4a34-97cc-7665c238ef10"
      },
      "source": [
        "print(\"Sparse Matrix form of test data : \\n\")\n",
        "print(tfidf_train.todense())\n",
        "\n",
        "print(\"\\nSparse Matrix form of test data : \\n\")\n",
        "print(tfidf_term_vectors.todense())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sparse Matrix form of test data : \n",
            "\n",
            "[[0.70710678 0.         0.70710678 0.        ]\n",
            " [0.         0.70710678 0.         0.70710678]]\n",
            "\n",
            "Sparse Matrix form of test data : \n",
            "\n",
            "[[0.         0.57735027 0.57735027 0.57735027]\n",
            " [0.         0.4472136  0.         0.89442719]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO4EHrGHOLuz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKaUI4wyWtcY"
      },
      "source": [
        "# TFIDF from scrach using coustom function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHKdWbjNOjYL"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cVt-R37XDnJ"
      },
      "source": [
        "documentA = 'the man went out for a walk'\n",
        "documentB = 'the children sat around the fire'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CabYbm8wXIWP"
      },
      "source": [
        "bagOfWordsA = documentA.split(' ')\n",
        "bagOfWordsB = documentB.split(' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS3TX-42XNC8"
      },
      "source": [
        "# remove duplicate words.\n",
        "uniqueWords = set(bagOfWordsA).union(set(bagOfWordsB))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7pStapyXQuh"
      },
      "source": [
        "#create a dictionary of words and their occurence for each document in the corpus (collection of documents)\n",
        "\n",
        "numOfWordsA = dict.fromkeys(uniqueWords, 0)\n",
        "for word in bagOfWordsA:\n",
        "    numOfWordsA[word] += 1\n",
        "    \n",
        "numOfWordsB = dict.fromkeys(uniqueWords, 0)\n",
        "for word in bagOfWordsB:\n",
        "    numOfWordsB[word] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJI3Am5RXwHO",
        "outputId": "47be504c-3d9a-4950-e664-6762d595a0b8"
      },
      "source": [
        "print(numOfWordsA)\n",
        "print(numOfWordsB)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'children': 0, 'the': 1, 'out': 1, 'went': 1, 'sat': 0, 'fire': 0, 'walk': 1, 'for': 1, 'around': 0, 'a': 1, 'man': 1}\n",
            "{'children': 1, 'the': 2, 'out': 0, 'went': 0, 'sat': 1, 'fire': 1, 'walk': 0, 'for': 0, 'around': 1, 'a': 0, 'man': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lLcJvz8YEwQ",
        "outputId": "aec8bd55-41ec-4dc6-cd8f-9de5ffcc15aa"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVgwdpTaR61B"
      },
      "source": [
        "# Term Frequency (TF)\n",
        "\n",
        "The number of times a word appears in a document divded by the total number of words in the document. Every document has its own term frequency.\n",
        "Image for post"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBNiKhSNR3Mz"
      },
      "source": [
        "def computeTF(wordDict, bagOfWords):\n",
        "    tfDict = {}\n",
        "    bagOfWordsCount = len(bagOfWords)\n",
        "    for word, count in wordDict.items():\n",
        "        tfDict[word] = count / float(bagOfWordsCount)\n",
        "    return tfDict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDw5QNgwScNh"
      },
      "source": [
        "#compute the term frequency for each of our documents.\n",
        "tfA = computeTF(numOfWordsA, bagOfWordsA)\n",
        "tfB = computeTF(numOfWordsB, bagOfWordsB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56jhP27PSkJ9",
        "outputId": "86d7b802-0d62-499c-fe7a-19463781ac1b"
      },
      "source": [
        "print(tfA)\n",
        "print(tfB)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'children': 0.0, 'the': 0.14285714285714285, 'out': 0.14285714285714285, 'went': 0.14285714285714285, 'sat': 0.0, 'fire': 0.0, 'walk': 0.14285714285714285, 'for': 0.14285714285714285, 'around': 0.0, 'a': 0.14285714285714285, 'man': 0.14285714285714285}\n",
            "{'children': 0.16666666666666666, 'the': 0.3333333333333333, 'out': 0.0, 'went': 0.0, 'sat': 0.16666666666666666, 'fire': 0.16666666666666666, 'walk': 0.0, 'for': 0.0, 'around': 0.16666666666666666, 'a': 0.0, 'man': 0.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc2tw-VUTR1_"
      },
      "source": [
        "# Inverse Data Frequency (IDF)\n",
        "The log of the number of documents divided by the number of documents that contain the word w. Inverse data frequency determines the weight of rare words across all documents in the corpus.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAl8NH8dTEtm"
      },
      "source": [
        "def computeIDF(documents):\n",
        "    import math\n",
        "    N = len(documents)\n",
        "    \n",
        "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
        "    for document in documents:\n",
        "        for word, val in document.items():\n",
        "            if val > 0:\n",
        "                idfDict[word] += 1\n",
        "    \n",
        "    for word, val in idfDict.items():\n",
        "        idfDict[word] = math.log(N / float(val))\n",
        "    return idfDict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtoG_yljTX_t"
      },
      "source": [
        "idfs = computeIDF([numOfWordsA, numOfWordsB])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAKwNi0dTwj8"
      },
      "source": [
        "def computeTFIDF(tfBagOfWords, idfs):\n",
        "    tfidf = {}\n",
        "    for word, val in tfBagOfWords.items():\n",
        "        tfidf[word] = val * idfs[word]\n",
        "    return tfidf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIK5PNFMT2ad"
      },
      "source": [
        "tfidfA = computeTFIDF(tfA, idfs)\n",
        "tfidfB = computeTFIDF(tfB, idfs)\n",
        "df = pd.DataFrame([tfidfA, tfidfB])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "65pBkoCCUjqo",
        "outputId": "7759b86a-ec46-4a7f-b008-5f450d437670"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>children</th>\n",
              "      <th>the</th>\n",
              "      <th>out</th>\n",
              "      <th>went</th>\n",
              "      <th>sat</th>\n",
              "      <th>fire</th>\n",
              "      <th>walk</th>\n",
              "      <th>for</th>\n",
              "      <th>around</th>\n",
              "      <th>a</th>\n",
              "      <th>man</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.099021</td>\n",
              "      <td>0.099021</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.099021</td>\n",
              "      <td>0.099021</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.099021</td>\n",
              "      <td>0.099021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.115525</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.115525</td>\n",
              "      <td>0.115525</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.115525</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   children  the       out      went  ...       for    around         a       man\n",
              "0  0.000000  0.0  0.099021  0.099021  ...  0.099021  0.000000  0.099021  0.099021\n",
              "1  0.115525  0.0  0.000000  0.000000  ...  0.000000  0.115525  0.000000  0.000000\n",
              "\n",
              "[2 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eccy9mH4Uw1F"
      },
      "source": [
        "#### Rather than manually implementing TF-IDF ourselves, we could use the class provided by sklearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "KeKgRaxBUuIw",
        "outputId": "52408349-55fb-4e6d-b8ba-8d955784731a"
      },
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform([documentA, documentB])\n",
        "feature_names = vectorizer.get_feature_names()\n",
        "dense = vectors.todense()\n",
        "denselist = dense.tolist()\n",
        "df = pd.DataFrame(denselist, columns=feature_names)\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>around</th>\n",
              "      <th>children</th>\n",
              "      <th>fire</th>\n",
              "      <th>for</th>\n",
              "      <th>man</th>\n",
              "      <th>out</th>\n",
              "      <th>sat</th>\n",
              "      <th>the</th>\n",
              "      <th>walk</th>\n",
              "      <th>went</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.42616</td>\n",
              "      <td>0.42616</td>\n",
              "      <td>0.42616</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.303216</td>\n",
              "      <td>0.42616</td>\n",
              "      <td>0.42616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.407401</td>\n",
              "      <td>0.407401</td>\n",
              "      <td>0.407401</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.407401</td>\n",
              "      <td>0.579739</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     around  children      fire      for  ...       sat       the     walk     went\n",
              "0  0.000000  0.000000  0.000000  0.42616  ...  0.000000  0.303216  0.42616  0.42616\n",
              "1  0.407401  0.407401  0.407401  0.00000  ...  0.407401  0.579739  0.00000  0.00000\n",
              "\n",
              "[2 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB8UM6rsU6KR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIvkE_BeK2eu"
      },
      "source": [
        "#co-occurrence matrix\n",
        "\n",
        "Before diving into the Co-Occurrence Matrix with a fixed context window, letâ€™s discuss the disadvantages of the other two Frequency-based techniques.\n",
        "Count Vector and TF-IDF do not capture the position in semantics, co-occurrences in the document, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY81jwh5K3KG",
        "outputId": "75b8cc1d-bbeb-4216-c78c-165237251db7"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "docs = ['this this this book',\n",
        "        'this cat good',\n",
        "        'cat good shit']\n",
        "count_model = CountVectorizer(ngram_range=(1,1)) # default unigram model\n",
        "X = count_model.fit_transform(docs)\n",
        "# X[X > 0] = 1 # run this line if you don't want extra within-text cooccurence (see below)\n",
        "Xc = (X.T * X) # this is co-occurrence matrix in sparse csr format\n",
        "Xc.setdiag(0) # sometimes you want to fill same word cooccurence to 0\n",
        "print(Xc.todense()) # print out matrix in dense format"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 0 3]\n",
            " [0 0 2 1 1]\n",
            " [0 2 0 1 1]\n",
            " [0 1 1 0 0]\n",
            " [3 1 1 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLBa3BnDLbsF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAn6beUwUyXo"
      },
      "source": [
        "Example:2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIMwlQMPLiMV"
      },
      "source": [
        "def co_occurrence(sentences, window_size):\n",
        "    from collections import defaultdict\n",
        "    \n",
        "    d = defaultdict(int)\n",
        "    vocab = set()\n",
        "    for text in sentences:\n",
        "        # preprocessing (use tokenizer instead)\n",
        "        text = text.lower().split()\n",
        "        # iterate over sentences\n",
        "        for i in range(len(text)):\n",
        "            token = text[i]\n",
        "            vocab.add(token)  # add to vocab\n",
        "            next_token = text[i+1 : i+1+window_size]\n",
        "            for t in next_token:\n",
        "                key = tuple( sorted([t, token]) )\n",
        "                d[key] += 1\n",
        "\n",
        "      # formulate the dictionary into dataframe\n",
        "    vocab = sorted(vocab) # sort vocab\n",
        "    df = pd.DataFrame(data=np.zeros((len(vocab), len(vocab)), dtype=np.int16),\n",
        "                      index=vocab,\n",
        "                      columns=vocab)\n",
        "    for key, value in d.items():\n",
        "        df.at[key[0], key[1]] = value\n",
        "        df.at[key[1], key[0]] = value\n",
        "    return df        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vScp5kq2L8gY"
      },
      "source": [
        "text = [\"I go to school every day by bus .\",\n",
        "            \"i go to theatre every night by bus\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYFQPZSnMBwS"
      },
      "source": [
        "df = co_occurrence(text, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "ht33CoRFMV76",
        "outputId": "8c4e149d-622f-4640-ab9d-df5adb2856d4"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>.</th>\n",
              "      <th>bus</th>\n",
              "      <th>by</th>\n",
              "      <th>day</th>\n",
              "      <th>every</th>\n",
              "      <th>go</th>\n",
              "      <th>i</th>\n",
              "      <th>night</th>\n",
              "      <th>school</th>\n",
              "      <th>theatre</th>\n",
              "      <th>to</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>.</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bus</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>by</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>day</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>every</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>go</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>i</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>night</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>school</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>theatre</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>to</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         .  bus  by  day  every  go  i  night  school  theatre  to\n",
              ".        0    1   1    0      0   0  0      0       0        0   0\n",
              "bus      1    0   2    1      0   0  0      1       0        0   0\n",
              "by       1    2   0    1      2   0  0      1       0        0   0\n",
              "day      0    1   1    0      1   0  0      0       1        0   0\n",
              "every    0    0   2    1      0   0  0      1       1        1   2\n",
              "go       0    0   0    0      0   0  2      0       1        1   2\n",
              "i        0    0   0    0      0   2  0      0       0        0   2\n",
              "night    0    1   1    0      1   0  0      0       0        1   0\n",
              "school   0    0   0    1      1   1  0      0       0        0   1\n",
              "theatre  0    0   0    0      1   1  0      1       0        0   1\n",
              "to       0    0   0    0      2   2  2      0       1        1   0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "BmyJYHn8N2hf",
        "outputId": "a8e484e9-e0ac-4bf3-dea0-b5de9866224e"
      },
      "source": [
        "df = co_occurrence(text, 3)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>.</th>\n",
              "      <th>bus</th>\n",
              "      <th>by</th>\n",
              "      <th>day</th>\n",
              "      <th>every</th>\n",
              "      <th>go</th>\n",
              "      <th>i</th>\n",
              "      <th>night</th>\n",
              "      <th>school</th>\n",
              "      <th>theatre</th>\n",
              "      <th>to</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>.</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bus</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>by</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>day</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>every</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>go</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>i</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>night</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>school</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>theatre</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>to</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         .  bus  by  day  every  go  i  night  school  theatre  to\n",
              ".        0    1   1    1      0   0  0      0       0        0   0\n",
              "bus      1    0   2    1      2   0  0      1       0        0   0\n",
              "by       1    2   0    1      2   0  0      1       1        1   0\n",
              "day      1    1   1    0      1   0  0      0       1        0   1\n",
              "every    0    2   2    1      0   2  0      1       1        1   2\n",
              "go       0    0   0    0      2   0  2      0       1        1   2\n",
              "i        0    0   0    0      0   2  0      0       1        1   2\n",
              "night    0    1   1    0      1   0  0      0       0        1   1\n",
              "school   0    0   1    1      1   1  1      0       0        0   1\n",
              "theatre  0    0   1    0      1   1  1      1       0        0   1\n",
              "to       0    0   0    1      2   2  2      1       1        1   0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXhH7ENpVlfo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF73iYExZBqH"
      },
      "source": [
        "# Embedding Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-e1oi-yZEHD"
      },
      "source": [
        "Example of Learning an Embedding\n",
        "\n",
        "we will define the documents and their class labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQNit_NwZpPA"
      },
      "source": [
        "# define documents\n",
        "docs = ['Well done!',\n",
        "\t\t'Good work',\n",
        "\t\t'Great effort',\n",
        "\t\t'nice work',\n",
        "\t\t'Excellent!',\n",
        "\t\t'Weak',\n",
        "\t\t'Poor effort!',\n",
        "\t\t'not good',\n",
        "\t\t'poor work',\n",
        "\t\t'Could have done better.']\n",
        "# define class labels\n",
        "labels = np.array([1,1,1,1,1,0,0,0,0,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeiLKZ4veHnb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sAl32eoeISL"
      },
      "source": [
        "from keras.preprocessing.text import one_hot\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGV4-rBqZtQN",
        "outputId": "76cdbb4c-5062-42d7-ef6d-9eabe8f82dae"
      },
      "source": [
        "# integer encode the documents\n",
        "vocab_size = 50\n",
        "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
        "print(encoded_docs)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[24, 13], [40, 34], [35, 30], [8, 34], [24], [9], [46, 30], [15, 40], [46, 34], [29, 27, 13, 41]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtO8b1CwfX1I"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ii2RFjbZaIni",
        "outputId": "52e3753d-df5e-421f-e7ab-f0a9d4e30156"
      },
      "source": [
        "# pad documents to a max length of 4 words\n",
        "max_length = 4\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "print(padded_docs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[24 13  0  0]\n",
            " [40 34  0  0]\n",
            " [35 30  0  0]\n",
            " [ 8 34  0  0]\n",
            " [24  0  0  0]\n",
            " [ 9  0  0  0]\n",
            " [46 30  0  0]\n",
            " [15 40  0  0]\n",
            " [46 34  0  0]\n",
            " [29 27 13 41]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGNB2Js1gBcE"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaMOsTEbaYah",
        "outputId": "448ef2a8-2b98-4c2f-a332-4bc005397b72"
      },
      "source": [
        "# define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# summarize the model\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 4, 8)              400       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 433\n",
            "Trainable params: 433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgeNrYo8gGuF",
        "outputId": "a7aff6ae-651a-4c8d-9c5a-17520c89c18f"
      },
      "source": [
        "# fit the model\n",
        "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
        "# evaluate the model\n",
        "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 80.000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNHpdgx3gOvE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPgbPmd_gxWN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}